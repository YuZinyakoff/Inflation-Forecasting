{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAQhSJ_fX9zT"
   },
   "source": [
    "# Первичный анализ ряда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10035,
     "status": "ok",
     "timestamp": 1746794557550,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "Misb_c5vX49b",
    "outputId": "e84e943e-e510-4d1f-b19a-21116fd1993b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima.arima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Настройки ---\n",
    "# Укажи путь к твоему файлу\n",
    "file_path = 'CPI.xlsx'\n",
    "# Названия колонок в твоем файле\n",
    "date_column = 'Дата'\n",
    "cpi_column = 'ИПЦ'\n",
    "# Определяем период для теста (например, последние 24 месяца)\n",
    "test_months = 24\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "# Чтение данных\n",
    "df = pd.read_excel(file_path, engine='openpyxl', sheet_name='ИПЦ')\n",
    "\n",
    "# Преобразование колонки с датой и установка ее как индекс\n",
    "df[date_column] = pd.to_datetime(df[date_column])\n",
    "df = df.set_index(date_column)\n",
    "\n",
    "# Выбор нужной колонки с ИПЦ\n",
    "cpi_data = df[[cpi_column]]\n",
    "\n",
    "# Удаление пропусков, если они есть (простой вариант)\n",
    "cpi_data = cpi_data.dropna()\n",
    "\n",
    "# Определение дат для разделения на train и test\n",
    "# data_do - последняя дата в данных\n",
    "data_do = cpi_data.index.max()\n",
    "# train_do - дата начала тестового периода\n",
    "# Отнимаем нужное количество месяцев от конца\n",
    "train_do_date = data_do - pd.DateOffset(months=test_months - 1)\n",
    "train_do = train_do_date.strftime('%Y-%m-%d') # Формат как в исходном коде\n",
    "\n",
    "print(f\"Данные используются до: {data_do.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Тестовый период начинается с: {train_do}\")\n",
    "\n",
    "# Разделение данных\n",
    "train = cpi_data[cpi_data.index < train_do]\n",
    "test = cpi_data[cpi_data.index >= train_do]\n",
    "\n",
    "print(f\"Размер обучающей выборки: {len(train)}\")\n",
    "print(f\"Размер тестовой выборки: {len(test)}\")\n",
    "\n",
    "# Проверим, что тестовая выборка имеет нужную длину\n",
    "if len(test) != test_months:\n",
    "    print(f\"Внимание: Длина тестовой выборки ({len(test)}) не равна {test_months} месяцев.\")\n",
    "    # Можно скорректировать train_do, если нужно точно test_months точек\n",
    "    train_do_date = cpi_data.index[-test_months]\n",
    "    train_do = train_do_date.strftime('%Y-%m-%d')\n",
    "    train = cpi_data[cpi_data.index < train_do]\n",
    "    test = cpi_data[cpi_data.index >= train_do]\n",
    "    print(f\"Скорректированный train_do: {train_do}, новая длина теста: {len(test)}\")\n",
    "\n",
    "\n",
    "# Выбираем только значения ИПЦ для обучения\n",
    "train_values = train[cpi_column]\n",
    "test_values = test[cpi_column]\n",
    "\n",
    "\n",
    "plot_start_date = '2018-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746794557553,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "o5kjw_HO08Lx"
   },
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1746794710211,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "VGOe_mXmZED5",
    "outputId": "9537155f-0c2a-4b3c-eceb-324f7e4c5a90"
   },
   "outputs": [],
   "source": [
    "# --- Настройки (если нужно поменять) ---\n",
    "cpi_value_column = 'ИПЦ' # Убедись, что это имя твоей колонки\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "# Используем переменную cpi_data из предыдущих шагов\n",
    "inflation_series = cpi_data[cpi_value_column]\n",
    "\n",
    "# Построение графика\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(inflation_series.index, inflation_series, label=f'{cpi_value_column}')\n",
    "plt.title('Темпы прироста потребительских цен, в процентах к предыдущему месяцу, сезонность устранена')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Значение')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1746794717345,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "kIDi4K4bZLHV",
    "outputId": "b619dd65-c5c6-4e28-f829-b4eef82d67bc"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# --- Настройки ---\n",
    "cpi_value_column = 'ИПЦ'\n",
    "significance_level = 0.05 # Уровень значимости\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "# Используем переменную cpi_data из предыдущих шагов\n",
    "inflation_series = train[cpi_value_column]\n",
    "\n",
    "print(\"--- Результаты теста Дики-Фуллера (ADF) ---\")\n",
    "# Проводим тест\n",
    "# autolag='AIC' позволяет тесту автоматически подобрать оптимальное число лагов\n",
    "adf_test_result = adfuller(inflation_series, autolag='AIC')\n",
    "\n",
    "# Извлекаем результаты\n",
    "adf_statistic = adf_test_result[0]\n",
    "p_value = adf_test_result[1]\n",
    "lags_used = adf_test_result[2]\n",
    "critical_values = adf_test_result[4]\n",
    "\n",
    "# Выводим результаты\n",
    "print(f'ADF Statistic: {adf_statistic:.4f}')\n",
    "print(f'p-value: {p_value:.4f}')\n",
    "print(f'Число использованных лагов: {lags_used}')\n",
    "print('Критические значения:')\n",
    "for key, value in critical_values.items():\n",
    "    print(f'\\t{key}: {value:.4f}')\n",
    "\n",
    "# Интерпретация результата\n",
    "print(\"\\nИнтерпретация:\")\n",
    "if p_value <= significance_level:\n",
    "    print(f\"p-value ({p_value:.4f}) меньше уровня значимости ({significance_level}).\")\n",
    "    print(\"Отвергаем нулевую гипотезу (H0). Ряд, скорее всего, СТАЦИОНАРЕН.\")\n",
    "else:\n",
    "    print(f\"p-value ({p_value:.4f}) больше уровня значимости ({significance_level}).\")\n",
    "    print(\"Не можем отвергнуть нулевую гипотезу (H0). Ряд, скорее всего, НЕ СТАЦИОНАРЕН.\")\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 689,
     "status": "ok",
     "timestamp": 1746794727099,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "wkjjV9HqZMko",
    "outputId": "496dc72f-d6cd-4559-e58a-a5d97bac7202"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# --- Настройки ---\n",
    "cpi_value_column = 'ИПЦ'\n",
    "lags_to_plot = 40 # Сколько лагов отображать на графике\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "# Используем переменную cpi_data из предыдущих шагов\n",
    "inflation_series = train[cpi_value_column]\n",
    "\n",
    "# Построение графика ACF\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "plot_acf(inflation_series, lags=lags_to_plot, ax=ax, title='Автокорреляционная функция (ACF)')\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1746794730186,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "hhB1h0MIZSKV",
    "outputId": "f2bb9bf8-69bc-4903-fc86-39417d2d8269"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "# --- Настройки ---\n",
    "cpi_value_column = 'ИПЦ'\n",
    "lags_to_plot = 40 # Сколько лагов отображать на графике\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "# Используем переменную cpi_data из предыдущих шагов\n",
    "inflation_series = train[cpi_value_column]\n",
    "\n",
    "# Построение графика PACF\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# method='ywm' (Yule-Walker Mle) - стандартный метод расчета\n",
    "plot_pacf(inflation_series, lags=lags_to_plot, method='ywm', ax=ax, title='Частичная автокорреляционная функция (PACF)')\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 910,
     "status": "ok",
     "timestamp": 1746795359275,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "gNI9LdmsGoJe",
    "outputId": "24d14d50-afa3-4eaa-d8c8-15ba784ae4b2"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Настройки ---\n",
    "cpi_value_column = 'ИПЦ'\n",
    "lags_to_plot = 40  # Сколько лагов отображать на графике\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "# Используем переменную train из предыдущих шагов\n",
    "inflation_series = train[cpi_value_column]\n",
    "\n",
    "# Создаем фигуру с двумя подграфиками (вертикально)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10, 6))\n",
    "\n",
    "# Построение ACF на первом подграфике\n",
    "plot_acf(inflation_series, lags=lags_to_plot, ax=ax1, title='Автокорреляционная функция (ACF)')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Построение PACF на втором подграфике\n",
    "plot_pacf(inflation_series, lags=lags_to_plot, method='ywm', ax=ax2, title='Частичная автокорреляционная функция (PACF)')\n",
    "ax2.grid(True)\n",
    "\n",
    "# Автоматическая регулировка отступов между графиками\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CDzkrg9ZXp_"
   },
   "source": [
    "* Визуальный анализ графика инфляции и результаты теста Дики-Фуллера (p-value << 0.05) указывают на стационарность временного ряда.\n",
    "* Графики автокорреляционной (ACF) и частичной автокорреляционной (PACF) функций показывают характерную для авторегрессионного процесса первого порядка (AR(1)) структуру: ACF постепенно затухает, а PACF резко обрывается после первого лага.\n",
    "* Следовательно, адекватной моделью для данного ряда может быть AR(1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGbSnheyiC0Z"
   },
   "source": [
    "# ARIMA и простые бенчмарки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1746795726164,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "ddbDoAfde8u1"
   },
   "outputs": [],
   "source": [
    "result_rmse = pd.DataFrame(columns=['method', 'rmse'])\n",
    "df_horizon_rmse = pd.DataFrame(columns=['method', 'horizon', 'rmse'])\n",
    "recursive_forecasts = {}\n",
    "horizons_to_evaluate = [1, 2, 3, 6, 12, 18, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1746795726979,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "T2vbfXv9gwHz",
    "outputId": "86046123-a05e-4dc6-fb70-3895907c8840"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 3: Простые Бенчмарки + Инициализация Результатов ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# train_values, test_values: pd.Series с обучающими и тестовыми значениями ИПЦ\n",
    "# train, test: pd.DataFrames с обучающими и тестовыми данными (для индексов и графиков)\n",
    "# test_months: Количество месяцев в тесте (24)\n",
    "# horizons_to_evaluate: Список горизонтов [1, 2, 3, 6, 12, 18, 24]\n",
    "# plot_start_date: Дата начала для графиков прогнозов\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "print(\"\\n--- Инициализация структур для результатов ---\")\n",
    "result_rmse = pd.DataFrame(columns=['method', 'rmse'])\n",
    "df_horizon_rmse = pd.DataFrame(columns=['method', 'horizon', 'rmse'])\n",
    "recursive_forecasts = {} # Словарь для ВСЕХ финальных прогнозов\n",
    "\n",
    "print(\"Структуры result_rmse, df_horizon_rmse, recursive_forecasts инициализированы.\")\n",
    "\n",
    "print(\"\\n--- Генерация и Оценка Простых Бенчмарков ---\")\n",
    "\n",
    "# --- Модель Mean ---\n",
    "model_name_mean = \"Mean\"\n",
    "mean_forecast_value = train_values.mean()\n",
    "forecast_mean = np.full(test_months, mean_forecast_value)\n",
    "recursive_forecasts[model_name_mean] = forecast_mean\n",
    "print(f\"\\n{model_name_mean}: Прогноз = {mean_forecast_value:.4f}\")\n",
    "overall_rmse_mean = np.sqrt(mean_squared_error(test_values, forecast_mean))\n",
    "print(f\"Общий RMSE: {overall_rmse_mean:.4f}\")\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([{'method': model_name_mean, 'rmse': overall_rmse_mean}])], ignore_index=True)\n",
    "horizon_results_list_mean = []\n",
    "print(\"RMSE по горизонтам:\")\n",
    "for h in horizons_to_evaluate:\n",
    "    rmse_h = np.sqrt(mean_squared_error(test_values[:h], forecast_mean[:h]))\n",
    "    print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "    horizon_results_list_mean.append({'method': model_name_mean, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, pd.DataFrame(horizon_results_list_mean)], ignore_index=True)\n",
    "\n",
    "# --- Модель Median ---\n",
    "model_name_median = \"Median\"\n",
    "median_forecast_value = train_values.median()\n",
    "forecast_median = np.full(test_months, median_forecast_value)\n",
    "recursive_forecasts[model_name_median] = forecast_median\n",
    "print(f\"\\n{model_name_median}: Прогноз = {median_forecast_value:.4f}\")\n",
    "overall_rmse_median = np.sqrt(mean_squared_error(test_values, forecast_median))\n",
    "print(f\"Общий RMSE: {overall_rmse_median:.4f}\")\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([{'method': model_name_median, 'rmse': overall_rmse_median}])], ignore_index=True)\n",
    "horizon_results_list_median = []\n",
    "print(\"RMSE по горизонтам:\")\n",
    "for h in horizons_to_evaluate:\n",
    "    rmse_h = np.sqrt(mean_squared_error(test_values[:h], forecast_median[:h]))\n",
    "    print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "    horizon_results_list_median.append({'method': model_name_median, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, pd.DataFrame(horizon_results_list_median)], ignore_index=True)\n",
    "\n",
    "# --- Модель Trend ---\n",
    "model_name_trend = \"Trend\"\n",
    "print(f\"\\n{model_name_trend}:\")\n",
    "try:\n",
    "    X_train_trend = np.arange(len(train_values)).reshape(-1, 1)\n",
    "    trend_model = LinearRegression().fit(X_train_trend, train_values)\n",
    "    X_test_trend = np.arange(len(train_values), len(train_values) + test_months).reshape(-1, 1)\n",
    "    forecast_trend = trend_model.predict(X_test_trend)\n",
    "    recursive_forecasts[model_name_trend] = forecast_trend\n",
    "    print(\"Прогноз сгенерирован.\")\n",
    "    overall_rmse_trend = np.sqrt(mean_squared_error(test_values, forecast_trend))\n",
    "    print(f\"Общий RMSE: {overall_rmse_trend:.4f}\")\n",
    "    result_rmse = pd.concat([result_rmse, pd.DataFrame([{'method': model_name_trend, 'rmse': overall_rmse_trend}])], ignore_index=True)\n",
    "    horizon_results_list_trend = []\n",
    "    print(\"RMSE по горизонтам:\")\n",
    "    for h in horizons_to_evaluate:\n",
    "        rmse_h = np.sqrt(mean_squared_error(test_values[:h], forecast_trend[:h]))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "        horizon_results_list_trend.append({'method': model_name_trend, 'horizon': h, 'rmse': rmse_h})\n",
    "    df_horizon_rmse = pd.concat([df_horizon_rmse, pd.DataFrame(horizon_results_list_trend)], ignore_index=True)\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при генерации/оценке прогноза Trend: {e}\")\n",
    "    recursive_forecasts[model_name_trend] = np.zeros(test_months) * np.nan\n",
    "\n",
    "print(\"\\n--- Простые бенчмарки рассчитаны и добавлены в таблицы ---\")\n",
    "\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_simple = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "# Сортируем колонки по текущему общему RMSE\n",
    "current_simple_order = result_rmse['method'].tolist()\n",
    "print(pivot_table_simple[current_simple_order].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1852,
     "status": "ok",
     "timestamp": 1746796428687,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "m2k6qAGKrgUv",
    "outputId": "b190e577-dc9f-4b63-ac20-8ffdbd434957"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 3А: Визуализация Простых Бенчмарков ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ БЛОКА 3 ---\n",
    "# train_values, test_values: pd.Series\n",
    "# train, test: pd.DataFrames\n",
    "# forecast_mean, forecast_median, forecast_trend: numpy arrays\n",
    "# df_horizon_rmse: DataFrame с результатами по горизонтам для Mean, Median, Trend\n",
    "# horizons_to_evaluate: Список горизонтов\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "print(\"\\n--- Визуализация Простых Бенчмарков ---\")\n",
    "\n",
    "# 1. График прогнозов на всем периоде\n",
    "plt.figure(figsize=(15, 7))\n",
    "# Рисуем весь реальный ряд (train + test)\n",
    "plt.plot(pd.concat([train_values[train_values.index >= plot_start_date], test_values]).index,\n",
    "         pd.concat([train_values[train_values.index >= plot_start_date], test_values]),\n",
    "         label='Реальные данные (Весь ряд)', color='grey', alpha=0.7)\n",
    "\n",
    "# Создаем полные ряды прогнозов для графика\n",
    "full_index = pd.concat([train_values, test_values]).index\n",
    "mean_full_forecast = pd.Series(np.nan, index=full_index)\n",
    "mean_full_forecast.loc[test.index] = forecast_mean # Заполняем только тестовый период\n",
    "\n",
    "median_full_forecast = pd.Series(np.nan, index=full_index)\n",
    "median_full_forecast.loc[test.index] = forecast_median\n",
    "\n",
    "trend_full_forecast = pd.Series(np.nan, index=full_index)\n",
    "trend_full_forecast.loc[test.index] = forecast_trend\n",
    "# Добавим линию тренда и на обучающий период для наглядности\n",
    "trend_train_pred = trend_model.predict(np.arange(len(train_values)).reshape(-1, 1))\n",
    "trend_full_forecast.loc[train.index] = trend_train_pred\n",
    "\n",
    "mean_full_forecast = mean_full_forecast[mean_full_forecast.index >= plot_start_date]\n",
    "median_full_forecast = median_full_forecast[median_full_forecast.index >= plot_start_date]\n",
    "trend_full_forecast = trend_full_forecast[trend_full_forecast.index >= plot_start_date]\n",
    "\n",
    "# Рисуем прогнозы\n",
    "plt.plot(mean_full_forecast.index, mean_full_forecast,\n",
    "         label=f'Прогноз Mean ({mean_forecast_value:.2f})', color='blue', linestyle='--')\n",
    "plt.plot(median_full_forecast.index, median_full_forecast,\n",
    "         label=f'Прогноз Median ({median_forecast_value:.2f})', color='black', linestyle='--')\n",
    "plt.plot(trend_full_forecast.index, trend_full_forecast,\n",
    "         label='Прогноз Trend', color='red', linestyle='--')\n",
    "\n",
    "\n",
    "plt.title('Прогнозы простых бенчмарков на тестовом периоде')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('ИПЦ (месячный рост)')\n",
    "# Ограничим ось Y для лучшей видимости прогнозов (можно закомментировать)\n",
    "# plt.ylim(min(test_values.min(), forecast_trend.min()) - 0.5, test_values.max() + 0.5)\n",
    "plt.axvline(train_values.index[-1], color='gray', linestyle=':', label='Начало теста') # Вертикальная линия\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. График RMSE vs Горизонт для простых бенчмарков\n",
    "plt.figure(figsize=(10, 5))\n",
    "simple_methods = [\"Mean\", \"Median\", \"Trend\"]\n",
    "simple_data_to_plot = df_horizon_rmse[df_horizon_rmse['method'].isin(simple_methods)]\n",
    "\n",
    "# Используем seaborn для разделения по 'method'\n",
    "sns.lineplot(data=simple_data_to_plot, x='horizon', y='rmse', hue='method',\n",
    "             marker='o', palette=['blue', 'black', 'red']) # Цвета как на графике выше\n",
    "\n",
    "plt.title('Зависимость RMSE от горизонта прогноза для простых бенчмарков')\n",
    "plt.xlabel('Горизонт прогноза (месяцы)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(horizons_to_evaluate)\n",
    "plt.grid(True)\n",
    "plt.legend(title='Модель')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15588,
     "status": "ok",
     "timestamp": 1746795778122,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "V19yCwRcZYO-",
    "outputId": "c17f7cd2-bc0c-4f7c-c105-f2b72e0077d5"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 4: Модель ARIMA ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima.arima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# train_values, test_values: pd.Series\n",
    "# train, test: pd.DataFrames\n",
    "# test_months, horizons_to_evaluate, plot_start_date\n",
    "# result_rmse, df_horizon_rmse, recursive_forecasts\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "model_name_arima = \"ARIMA\"\n",
    "\n",
    "print(f\"\\n--- Обучение и Прогнозирование: {model_name_arima} ---\")\n",
    "\n",
    "# 1. Подбор и обучение модели\n",
    "stepwise_model_arima = auto_arima(train_values,\n",
    "                                  start_p=1, start_q=1, max_p=5, max_q=5,\n",
    "                                  m=1, seasonal=False, d=0,\n",
    "                                  test='adf', trace=False,\n",
    "                                  error_action='ignore', suppress_warnings=True,\n",
    "                                  stepwise=True, information_criterion='aic')\n",
    "print(f\"\\nВыбранная модель: {stepwise_model_arima.order} {stepwise_model_arima.seasonal_order}\")\n",
    "\n",
    "# 2. Генерация рекурсивного прогноза\n",
    "forecast_arima = stepwise_model_arima.predict(n_periods=test_months)\n",
    "recursive_forecasts[model_name_arima] = forecast_arima[:test_months]\n",
    "print(f\"Прогноз {model_name_arima} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "# 3. Оценка RMSE\n",
    "overall_rmse_arima = np.sqrt(mean_squared_error(test_values, forecast_arima))\n",
    "print(f\"\\nОбщий RMSE на тесте для {model_name_arima}: {overall_rmse_arima:.4f}\")\n",
    "\n",
    "# Добавляем/Обновляем общий RMSE\n",
    "result_rmse = result_rmse[result_rmse['method'] != model_name_arima]\n",
    "result_arima_entry = {'method': model_name_arima, 'rmse': overall_rmse_arima}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_arima_entry])], ignore_index=True)\n",
    "\n",
    "# Расчет и добавление RMSE по горизонтам\n",
    "print(\"RMSE по горизонтам:\")\n",
    "df_horizon_rmse = df_horizon_rmse[df_horizon_rmse['method'] != model_name_arima]\n",
    "horizon_results_list_arima = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(test_values):\n",
    "        forecast_h = forecast_arima[:h]\n",
    "        actual_h = test_values[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h, forecast_h))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\") # Вывод промежуточного RMSE\n",
    "        horizon_results_list_arima.append({'method': model_name_arima, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse_arima = pd.DataFrame(horizon_results_list_arima)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_arima], ignore_index=True)\n",
    "print(\"Результаты RMSE по горизонтам добавлены/обновлены.\")\n",
    "\n",
    "# 4. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2)\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label=f'Прогноз {model_name_arima}', color='blue', linestyle='--')\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_arima}')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. График RMSE vs Горизонт (только для этой модели)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_horizon_rmse_arima['horizon'], df_horizon_rmse_arima['rmse'], marker='o', linestyle='-')\n",
    "plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_arima}')\n",
    "plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "\n",
    "print(f\"--- Анализ {model_name_arima} завершен ---\")\n",
    "\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_current = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "current_order = result_rmse['method'].tolist() # Порядок по текущему общему RMSE\n",
    "# Добавляем и сортируем колонки\n",
    "for method in current_order:\n",
    "     if method not in pivot_table_current.columns: pivot_table_current[method] = np.nan\n",
    "print(pivot_table_current[current_order].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1746800533625,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "2OvUAfK4I-9z",
    "outputId": "5e15df18-bbff-4bfa-8835-d33b97a32b29"
   },
   "outputs": [],
   "source": [
    "print(stepwise_model_arima.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McR_mF5tiVbD"
   },
   "source": [
    "\n",
    "* Применение автоматического подбора с помощью `auto_arima` (при `d=0`) выбрало модель **ARIMA(1,0,0)** как показавшую наименьшую ошибку RMSE (0.2627) на тестовой выборке. Этот выбор **согласуется** с выводами ручного анализа ряда, который подтвердил **стационарность** (тест ADF) и выявил **структуру AR(1)** (анализ ACF/PACF).\n",
    "\n",
    "* Диагностика остатков модели выявила **отсутствие в них автокорреляции** (тест Льюнга-Бокса, Prob(Q) >> 0.05). Это **ключевой положительный результат**, поскольку он означает, что модель успешно извлекла из данных предсказуемую линейную структуру, и оставшийся \"шум\" не содержит явных паттернов, которые можно было бы использовать для улучшения *линейного* прогноза.\n",
    "\n",
    "* В то же время, тесты остатков показали **статистически значимые отклонения от нормального распределения** (тест Харке-Бера, Prob(JB) << 0.05) и наличие **гетероскедастичности** (Prob(H) << 0.05). Хотя эти нарушения классических предпосылок важны для точности доверительных интервалов и статистической значимости *коэффициентов* модели, они **менее критичны для задачи точечного прогнозирования**, особенно при сравнении моделей по метрикам типа RMSE. Отсутствие автокорреляции в остатках позволяет считать линейную часть модели адекватной.\n",
    "\n",
    "* Анализ ошибки прогноза на тестовой выборке показал немонотонную зависимость RMSE от горизонта: ошибка была выше на коротких горизонтах (1-3 мес., RMSE > 0.32), достигала минимума на горизонте 12 месяцев (RMSE ≈ 0.259) и незначительно возрастала далее, составляя 0.263 на полном 24-месячном горизонте.\n",
    "\n",
    "* Учитывая лучший общий RMSE (0.263) среди рассмотренных ARIMA-вариантов и отсутствие автокорреляции остатков, модель ARIMA(1,0,0) принимается как обоснованный и сильный бенчмарк для дальнейшего сравнения с моделями машинного обучения. Анализ по горизонтам будет важен для детального сопоставления производительности разных методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Y7NwKpjijS4"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw-dcMS7iosi"
   },
   "source": [
    "\n",
    "**Генерация признаков для моделей машинного обучения**\n",
    "\n",
    "**Цель:**  \n",
    "Создать набор информативных признаков для ML-моделей, используя **только историю самого ряда инфляции ('t')**. Это обеспечит корректность сравнения с моделью ARIMA, которая также использует только историю ряда.\n",
    "\n",
    "**Выбор признаков**\n",
    "\n",
    "Основан на подходе из статьи-источника и распространённых практиках анализа временных рядов:\n",
    "\n",
    "1. **Лаги ряда (`t-1`, `t-6`, `t-12`)**  \n",
    "   - Предполагается, что прошлые значения инфляции (особенно за предыдущий месяц, полгода и год) влияют на текущее значение.  \n",
    "   - Лаг `t-1` особенно важен для рядов с AR(1)-структурой.\n",
    "\n",
    "2. **Скользящие статистики** (среднее и стандартное отклонение за 3, 6, 12 месяцев)  \n",
    "   - Помогают уловить:  \n",
    "     - Локальный уровень инфляции (`t_mean_lag`),  \n",
    "     - Волатильность (`t_std_lag`) за периоды, соответствующие кварталу, полугодию и году.  \n",
    "   - Рассчитываются со сдвигом на 1 период назад (`.shift(1)`), чтобы избежать утечки данных.\n",
    "\n",
    "3. **Порядковый номер месяца (`month`)**  \n",
    "   - Добавляется для учёта возможных остаточных календарных эффектов, не уловленных другими признаками.\n",
    "\n",
    "**Ограничение набора признаков**\n",
    "\n",
    "Сознательно **не включаются все возможные лаги и окна**, чтобы:  \n",
    "- Избежать \"проклятия размерности\" и переобучения на доступном объёме данных (~250 наблюдений),  \n",
    "- Сохранить интерпретируемость модели,  \n",
    "- Следовать методологии статьи-источника для сопоставимости.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1746800538066,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "ZQFUEybQh023",
    "outputId": "14e30030-b241-41f6-d74d-b94ef34c1500"
   },
   "outputs": [],
   "source": [
    "# --- Настройки ---\n",
    "cpi_value_column = 'ИПЦ' # Имя столбца с инфляцией\n",
    "\n",
    "lags_to_create = [1, 2, 3, 6, 12]\n",
    "\n",
    "rolling_windows = [3, 6, 12]\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "\n",
    "data_ml = cpi_data[[cpi_value_column]].copy()\n",
    "data_ml = data_ml.rename(columns={cpi_value_column: 't'})\n",
    "\n",
    "print(\"Исходные данные для ML:\")\n",
    "data_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1746800540022,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "99QR2PLxiynd",
    "outputId": "ff24b38f-a7f6-49b9-c369-75eedf811e8f"
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Создание лаговых признаков ---\")\n",
    "for lag in lags_to_create:\n",
    "    data_ml[f't-{lag}'] = data_ml['t'].shift(lag)\n",
    "    print(f\"Создан признак t-{lag}\")\n",
    "\n",
    "print(\"\\nDataFrame с лагами (начало):\")\n",
    "print(data_ml.head(max(lags_to_create) + 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1746800542606,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "_M5PmeAdi1gE",
    "outputId": "ea4e91f4-06c8-4cb2-d195-ca76c379d1d8"
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Создание скользящих статистик ---\")\n",
    "\n",
    "# Используем исходный ряд 't' для расчета\n",
    "target_series = data_ml['t']\n",
    "\n",
    "for window in rolling_windows:\n",
    "    # Скользящее среднее\n",
    "    rolling_mean = target_series.rolling(window=window).mean()\n",
    "    data_ml[f't_mean_lag{window}'] = rolling_mean.shift(1) # Применяем shift(1)\n",
    "    print(f\"Создан признак t_mean_lag{window}\")\n",
    "\n",
    "    # Скользящее стандартное отклонение\n",
    "    rolling_std = target_series.rolling(window=window).std()\n",
    "    data_ml[f't_std_lag{window}'] = rolling_std.shift(1) # Применяем shift(1)\n",
    "    print(f\"Создан признак t_std_lag{window}\")\n",
    "\n",
    "print(\"\\nDataFrame со статистиками (начало):\")\n",
    "# Покажем чуть больше строк, чтобы увидеть, как заполняются статистики\n",
    "print(data_ml.head(max(rolling_windows) + max(lags_to_create) + 2)) # Примерно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR4mf8IQi5y3"
   },
   "source": [
    "**Кодирование признака \"Месяц\"**\n",
    "\n",
    "Для учета возможных сезонных или календарных эффектов, которые могут оставаться в данных, в модель добавляется информация о месяце. Вместо простого порядкового номера (1-12), который вносит искусственную линейную зависимость и некорректно отражает близость декабря к январю, используется **циклическое кодирование**.\n",
    "\n",
    "Месяц представляется двумя новыми признаками с помощью синуса и косинуса:\n",
    "\n",
    "*   `month_sin = sin(2 * pi * month / 12)`\n",
    "*   `month_cos = cos(2 * pi * month / 12)`\n",
    "\n",
    "**Преимущества такого подхода:**\n",
    "\n",
    "1.  **Отражение цикличности:** Эта пара признаков уникально идентифицирует каждый месяц и правильно передает модели информацию о том, что 12-й месяц близок к 1-му (их значения sin/cos близки).\n",
    "2.  **Непрерывность:** Признаки являются непрерывными, что удобно для большинства ML алгоритмов.\n",
    "3.  **Отсутствие искусственного порядка:** Модель не будет ошибочно считать, что декабрь \"больше\" января.\n",
    "\n",
    "**Интерпретация:** Модель будет использовать эти два признака (`month_sin`, `month_cos`) для выявления любых паттернов, связанных с месяцем года. Например, определенная комбинация высоких значений `month_sin` и низких `month_cos` может соответствовать летним месяцам и быть связана с определенным уровнем инфляции, отличающимся от зимних месяцев (где комбинация sin/cos будет другой). Интерпретация влияния конкретного месяца становится менее прямой, чем с дамми-переменными, но модель получает более адекватное представление о времени года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1746800546357,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "urEHRze3i8uJ",
    "outputId": "53e87e18-1d4e-4149-aaab-6b529f09f518"
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Добавление циклических признаков месяца ---\")\n",
    "# Получаем номер месяца (1-12)\n",
    "month_num = data_ml.index.month\n",
    "# Вычисляем синус и косинус компоненты\n",
    "data_ml['month_sin'] = np.sin(2 * np.pi * month_num / 12)\n",
    "data_ml['month_cos'] = np.cos(2 * np.pi * month_num / 12)\n",
    "\n",
    "print(\"Созданы признаки 'month_sin' и 'month_cos'\")\n",
    "\n",
    "data_ml[['t', 'month_sin', 'month_cos']] # Посмотрим на новые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1746800549183,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "zR8r2Tp3jDbV",
    "outputId": "5bf5320a-c8bb-42c7-bdb4-270a63a262b8"
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Удаление строк с NaN ---\")\n",
    "initial_rows = len(data_ml)\n",
    "data_ml.dropna(inplace=True)\n",
    "final_rows = len(data_ml)\n",
    "print(f\"Удалено {initial_rows - final_rows} строк с NaN.\")\n",
    "print(f\"Итоговый размер DataFrame для ML: {data_ml.shape}\")\n",
    "print(\"\\nТипы данных:\")\n",
    "print(data_ml.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1746800551362,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "icTRCnI9jGTW",
    "outputId": "d1206212-a9fa-4919-c03e-d471f58d3b7d"
   },
   "outputs": [],
   "source": [
    "data_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1746800553381,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "LmhgtuHHjME1",
    "outputId": "77786248-bc44-4889-823d-4adb4c97d37f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# --- Настройки (из предыдущих шагов) ---\n",
    "# Убедись, что train_do содержит правильную дату начала тестового периода\n",
    "# train_do = '2023-02-01' # Пример, возьми свою дату\n",
    "target_column = 't'\n",
    "# Количество сплитов для TimeSeriesSplit (как в статье)\n",
    "n_cv_splits = 10\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "# 1. Разделение данных на train и test\n",
    "print(f\"--- Разделение данных (дата среза: {train_do}) ---\")\n",
    "train_ml = data_ml[data_ml.index < train_do]\n",
    "test_ml = data_ml[data_ml.index >= train_do]\n",
    "\n",
    "print(f\"Размер обучающей выборки ML: {train_ml.shape}\")\n",
    "print(f\"Размер тестовой выборки ML: {test_ml.shape}\")\n",
    "\n",
    "# Проверка, что размер тестовой выборки совпадает с ожидаемым (test_months)\n",
    "if len(test_ml) != test_months:\n",
    "     print(f\"Предупреждение: Фактическая длина тестовой ML выборки ({len(test_ml)}) отличается от test_months ({test_months})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1746800556046,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "phr-M5zpjPWe",
    "outputId": "56979b27-9566-40f2-b012-3212f168cb83"
   },
   "outputs": [],
   "source": [
    "# 2. Определение X и y\n",
    "print(\"\\n--- Определение X (признаки) и y (цель) ---\")\n",
    "X_train = train_ml.drop(target_column, axis=1)\n",
    "y_train = train_ml[target_column]\n",
    "\n",
    "X_test = test_ml.drop(target_column, axis=1)\n",
    "y_test = test_ml[target_column] # Это наши реальные значения для сравнения прогнозов\n",
    "\n",
    "print(\"Размеры X_train:\", X_train.shape)\n",
    "print(\"Размеры y_train:\", y_train.shape)\n",
    "print(\"Размеры X_test:\", X_test.shape)\n",
    "print(\"Размеры y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1746800556981,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "quIH4AGDjRU4",
    "outputId": "9ca47f4f-5f3f-4fa7-cd52-22b420a3b78e"
   },
   "outputs": [],
   "source": [
    "# 3. Масштабирование признаков (для линейных моделей и LSTM)\n",
    "print(\"\\n--- Масштабирование признаков (MinMaxScaler) ---\")\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) # Используем стандартный диапазон\n",
    "# Обучаем scaler ТОЛЬКО на обучающих признаках X_train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Применяем scaler к обучающей и тестовой выборкам для получения X_train_m, X_test_m\n",
    "X_train_m = scaler.transform(X_train)\n",
    "X_test_m = scaler.transform(X_test)\n",
    "\n",
    "# Преобразуем обратно в DataFrame для удобства (опционально, но полезно)\n",
    "X_train_m = pd.DataFrame(X_train_m, index=X_train.index, columns=X_train.columns)\n",
    "X_test_m = pd.DataFrame(X_test_m, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "print(\"Масштабирование выполнено.\")\n",
    "print(\"Созданы X_train_m и X_test_m.\")\n",
    "# print(\"Пример X_train_m:\", X_train_m.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1746800559363,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "ap8OnFmgjT2Q",
    "outputId": "209da568-9ff8-4e43-c788-fca962bffd07"
   },
   "outputs": [],
   "source": [
    "# 4. Настройка TimeSeriesSplit для кросс-валидации (код тот же)\n",
    "print(\"\\n--- Настройка TimeSeriesSplit ---\")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_cv_splits)\n",
    "print(f\"TimeSeriesSplit настроен с {tscv.get_n_splits()} сплитами.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1746800561111,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "2N1MMZNFjXcI",
    "outputId": "999d1902-f757-437c-9cda-ce3f227ef23d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Настройки (копируем из блока Feature Engineering) ---\n",
    "lags_to_create = [1,2, 3, 6, 12]\n",
    "rolling_windows = [3, 6, 12]\n",
    "# Имена колонок признаков (в том порядке, как они в X_train)\n",
    "# Важно: Получи этот порядок из твоего готового X_train\n",
    "# Например: feature_order = X_train.columns.tolist()\n",
    "# Пока зададим вручную на основе нашего кода:\n",
    "feature_order = [\n",
    "    't-1','t-2', 't-3', 't-6', 't-12',\n",
    "    't_mean_lag3', 't_std_lag3',\n",
    "    't_mean_lag6', 't_std_lag6',\n",
    "    't_mean_lag12', 't_std_lag12',\n",
    "    'month_sin', 'month_cos'\n",
    "]\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "\n",
    "def calculate_features_for_step(history_series: pd.Series):\n",
    "    \"\"\"\n",
    "    Рассчитывает набор признаков для прогноза СЛЕДУЮЩЕГО шага\n",
    "    на основе предоставленной истории.\n",
    "\n",
    "    Args:\n",
    "        history_series (pd.Series): Временной ряд значений (y) с DatetimeIndex,\n",
    "                                     включающий все данные до момента,\n",
    "                                     *предшествующего* тому, для которого нужны признаки.\n",
    "                                     Последняя точка - это y(t-1).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Строка признаков для прогнозирования y(t),\n",
    "                   индексированная именами признаков в правильном порядке.\n",
    "                   Или None, если истории недостаточно.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    n = len(history_series)\n",
    "    next_index = history_series.index[-1] + pd.DateOffset(months=1)\n",
    "\n",
    "    # Рассчитываем лаги (относительно ПОСЛЕДНЕЙ точки в history_series, т.е. y(t-1))\n",
    "    for lag in lags_to_create:\n",
    "        if n >= lag:\n",
    "            features[f't-{lag}'] = history_series.iloc[-lag]\n",
    "        else:\n",
    "            features[f't-{lag}'] = np.nan # Недостаточно истории\n",
    "\n",
    "    # Рассчитываем скользящие статистики (окно ЗАКАНЧИВАЕТСЯ на последней точке history_series)\n",
    "    # Это соответствует .shift(1) при создании обучающей выборки\n",
    "    for window in rolling_windows:\n",
    "        if n >= window:\n",
    "            window_data = history_series.iloc[-window:]\n",
    "            features[f't_mean_lag{window}'] = window_data.mean()\n",
    "            features[f't_std_lag{window}'] = window_data.std()\n",
    "        else:\n",
    "            features[f't_mean_lag{window}'] = np.nan\n",
    "            features[f't_std_lag{window}'] = np.nan\n",
    "\n",
    "    # Рассчитываем циклические признаки для СЛЕДУЮЩЕГО месяца\n",
    "    next_month_num = next_index.month\n",
    "    features['month_sin'] = np.sin(2 * np.pi * next_month_num / 12)\n",
    "    features['month_cos'] = np.cos(2 * np.pi * next_month_num / 12)\n",
    "\n",
    "    # Собираем результат в Series и проверяем на NaN\n",
    "    features_series = pd.Series(features)\n",
    "    if features_series.isnull().any():\n",
    "        # print(f\"Warning: NaN в признаках для индекса {next_index}. История слишком коротка?\")\n",
    "        # Решаем, как обрабатывать NaN - пока вернем None\n",
    "        # В рекурсивном прогнозе NaN быть не должно, т.к. стартуем с полной истории\n",
    "        return None\n",
    "\n",
    "    # Возвращаем признаки в правильном порядке\n",
    "    try:\n",
    "        return features_series[feature_order]\n",
    "    except KeyError as e:\n",
    "        print(f\"Ошибка: Несовпадение имен признаков! {e}\")\n",
    "        print(\"Ожидаемый порядок:\", feature_order)\n",
    "        print(\"Сгенерированные признаки:\", features_series.index.tolist())\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Тестирование функции ---\n",
    "print(\"--- Тестирование функции calculate_features_for_step ---\")\n",
    "# Возьмем конец y_train для примера\n",
    "test_history = y_train.iloc[-15:] # Последние 15 точек обучающей выборки\n",
    "print(\"Последние точки истории для теста функции:\")\n",
    "print(test_history)\n",
    "\n",
    "# Рассчитаем признаки для ПЕРВОГО шага прогноза (т.е. для первого индекса в y_test)\n",
    "first_step_features = calculate_features_for_step(test_history)\n",
    "\n",
    "print(\"\\nПризнаки, рассчитанные для первого шага прогноза:\")\n",
    "if first_step_features is not None:\n",
    "    print(first_step_features.round(4))\n",
    "    # Сравним с первой строкой X_test (должны быть очень близки, если test_history - это конец y_train)\n",
    "    print(\"\\nПервая строка X_test (для сравнения):\")\n",
    "    print(X_test.iloc[0].round(4))\n",
    "\n",
    "    # Проверим совпадение (допускаем небольшие погрешности вычислений)\n",
    "    if np.allclose(first_step_features.fillna(0), X_test.iloc[0].fillna(0), atol=1e-6):\n",
    "         print(\"\\nТест пройден: Рассчитанные признаки совпадают с первой строкой X_test.\")\n",
    "    else:\n",
    "         print(\"\\nТест НЕ пройден: Рассчитанные признаки НЕ совпадают с первой строкой X_test.\")\n",
    "         # Выведем разницу для отладки\n",
    "         # print(\"Разница:\")\n",
    "         # print((first_step_features - X_test.iloc[0]).round(4))\n",
    "\n",
    "else:\n",
    "    print(\"Функция вернула None, возможно, истории недостаточно.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1746800564939,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "lpVe89MajaWU"
   },
   "outputs": [],
   "source": [
    "def recursive_predict(model, initial_history_series: pd.Series, n_steps: int,\n",
    "                      feature_calculator, feature_order: list, scaler=None):\n",
    "    \"\"\"\n",
    "    Генерирует рекурсивный многошаговый прогноз.\n",
    "\n",
    "    Args:\n",
    "        model: Обученная ML модель (с методом predict).\n",
    "        initial_history_series (pd.Series): Исходная история y до начала прогноза.\n",
    "        n_steps (int): Количество шагов прогноза.\n",
    "        feature_calculator (function): Функция, рассчитывающая признаки для шага.\n",
    "        feature_order (list): Порядок колонок признаков, ожидаемый моделью.\n",
    "        scaler (MinMaxScaler, optional): Scaler для масштабирования признаков\n",
    "                                          и обратного масштабирования прогноза,\n",
    "                                          если модель обучалась на scaled данных.\n",
    "                                          Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Массив с прогнозами на n_steps шагов.\n",
    "    \"\"\"\n",
    "    # Копируем историю, чтобы не изменять оригинал\n",
    "    current_history = initial_history_series.copy()\n",
    "    predictions = []\n",
    "\n",
    "    print(f\"Запуск рекурсивного прогноза для {model.__class__.__name__} на {n_steps} шагов...\")\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        # 1. Рассчитать признаки для текущего шага (прогноза y(t))\n",
    "        #    на основе истории до t-1\n",
    "        features_for_step = feature_calculator(current_history)\n",
    "\n",
    "        if features_for_step is None:\n",
    "            print(f\"Ошибка: Не удалось рассчитать признаки на шаге {i+1}. Прерывание.\")\n",
    "            # Заполняем оставшиеся прогнозы NaN или последним значением\n",
    "            predictions.extend([predictions[-1] if predictions else np.nan] * (n_steps - i))\n",
    "            break\n",
    "\n",
    "        # 2. Подготовить признаки для модели\n",
    "        # Преобразуем в DataFrame с одной строкой и нужным порядком колонок\n",
    "        features_df = features_for_step.to_frame().T\n",
    "        # Масштабируем, если scaler предоставлен\n",
    "        if scaler:\n",
    "            features_scaled = scaler.transform(features_df)\n",
    "            model_input = features_scaled\n",
    "        else:\n",
    "            model_input = features_df # Используем исходные признаки\n",
    "\n",
    "        # 3. Сделать прогноз на 1 шаг вперед\n",
    "        try:\n",
    "             # model.predict ожидает 2D массив\n",
    "            next_pred = model.predict(model_input)[0]\n",
    "        except Exception as e:\n",
    "             print(f\"Ошибка предсказания модели на шаге {i+1}: {e}\")\n",
    "             # Заполняем NaN или последним значением\n",
    "             next_pred_final = predictions[-1] if predictions else np.nan\n",
    "             predictions.extend([next_pred_final] * (n_steps - i))\n",
    "             break\n",
    "\n",
    "        # 4. Обратно масштабировать прогноз НЕ НУЖНО, если модель предсказывает y\n",
    "        #    Масштабирование/обратное масштабирование применяется к ПРИЗНАКАМ (X),\n",
    "        #    а не к целевой переменной (y) внутри этого цикла.\n",
    "        #    ОБУЧЕНИЕ модели происходило на y_train (немасштабированном)\n",
    "        #    или на y_train_lstm (масштабированном для LSTM - это особый случай).\n",
    "        #    !!! ВАЖНО: Убедимся, что все наши ML модели обучались на y_train !!!\n",
    "        #    Да, Ridge, Lasso, RF, XGBoost обучались на y_train. LSTM - особый случай.\n",
    "        next_pred_final = next_pred # Прогноз уже в нужном масштабе\n",
    "\n",
    "        # 5. Сохранить прогноз\n",
    "        predictions.append(next_pred_final)\n",
    "\n",
    "        # 6. Добавить прогноз к истории для следующего шага\n",
    "        next_index = current_history.index[-1] + pd.DateOffset(months=1)\n",
    "        # Используем pd.concat\n",
    "        current_history = pd.concat([current_history, pd.Series([next_pred_final], index=[next_index])])\n",
    "\n",
    "        # Вывод прогресса (опционально)\n",
    "        # if (i + 1) % 6 == 0:\n",
    "        #      print(f\"  Шаг {i+1}/{n_steps} выполнен.\")\n",
    "\n",
    "    print(f\"Рекурсивный прогноз для {model.__class__.__name__} завершен.\")\n",
    "    return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNo57Xy5m5G9"
   },
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6750,
     "status": "ok",
     "timestamp": 1746800577904,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "uvVKEs71mzVn",
    "outputId": "a6bfd774-0e0d-4b0b-9e07-1ec28f26b82b"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 7: Модель Ridge (Обучение с hyperopt + Рекурсивный Прогноз) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "# Убираем GridSearchCV, добавляем hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Убедимся, что tscv определен из предыдущих блоков\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# X_train_m, y_train - масштабированные DataFrame и Series для обучения\n",
    "# X_test_m - масштабированный DataFrame для теста (если scaler используется в recursive_predict)\n",
    "# y_test - Series с реальными значениями на тесте\n",
    "# tscv - настроенный TimeSeriesSplit\n",
    "# scaler - обученный MinMaxScaler (если используется)\n",
    "# calculate_features_for_step - функция расчета признаков\n",
    "# feature_order - список с порядком признаков\n",
    "# test_months - количество месяцев в тесте (24)\n",
    "# horizons_to_evaluate - список горизонтов [1, 2, 3, 6, 12, 18, 24]\n",
    "# result_rmse, df_horizon_rmse: Инициализированные DataFrames для результатов\n",
    "# recursive_forecasts: Инициализированный словарь для прогнозов\n",
    "# plot_start_date: Дата начала для графиков прогнозов\n",
    "# forecast_arima: Прогноз ARIMA (для графика)\n",
    "# train_values, test_values - исходные (немасштабированные) ряды для графиков\n",
    "# random_seed - для воспроизводимости (например, 42)\n",
    "# recursive_predict - функция рекурсивного прогноза\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "# --- Дополнительные настройки ---\n",
    "model_name_ridge = \"Ridge_Recursive\" # Новое имя\n",
    "MAX_EVALS_HYPEROPT = 50 # Количество итераций для hyperopt (можно изменить)\n",
    "# --- Конец Дополнительных настроек ---\n",
    "\n",
    "print(f\"\\n--- Обучение и Прогнозирование: {model_name_ridge} ---\")\n",
    "\n",
    "# 1. Определяем пространство поиска для hyperopt\n",
    "#    Используем loguniform, так как alpha может меняться на порядки и > 0.\n",
    "#    Задаем широкий диапазон, например, от 1e-4 до 100 (в логарифмах)\n",
    "space_ridge = {\n",
    "    'alpha': hp.loguniform('alpha', np.log(0.0001), np.log(100.0))\n",
    "}\n",
    "\n",
    "# 2. Определяем целевую функцию (objective) для hyperopt\n",
    "def objective_ridge(params):\n",
    "    \"\"\"\n",
    "    Целевая функция для hyperopt. Обучает Ridge с заданным alpha\n",
    "    и оценивает его с помощью TimeSeriesSplit кросс-валидации.\n",
    "    Возвращает средний RMSE по фолдам.\n",
    "    \"\"\"\n",
    "    current_alpha = params['alpha']\n",
    "\n",
    "    model = Ridge(alpha=current_alpha)\n",
    "\n",
    "    rmses = []\n",
    "    # Цикл кросс-валидации по фолдам TimeSeriesSplit\n",
    "    # Убедись, что X_train_m и y_train - это те данные, на которых ты хочешь валидироваться\n",
    "    # и что они имеют совместимые типы (например, оба Pandas или оба NumPy)\n",
    "    try:\n",
    "        for train_idx, val_idx in tscv.split(X_train_m):\n",
    "            # Используем .iloc, если X_train_m и y_train - Pandas объекты\n",
    "            X_fold_train, X_fold_val = X_train_m.iloc[train_idx], X_train_m.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            preds = model.predict(X_fold_val)\n",
    "\n",
    "            # Обработка возможных NaN или бесконечностей в прогнозах или реальных значениях\n",
    "            if not np.all(np.isfinite(preds)) or not np.all(np.isfinite(y_fold_val.values)):\n",
    "                 print(f\"Warning: Non-finite values found in fold predictions or actuals for alpha={current_alpha}. Skipping fold.\")\n",
    "                 # Можно вернуть очень большое значение ошибки, чтобы hyperopt избегал таких параметров\n",
    "                 # return {'loss': 1e10, 'status': STATUS_OK, 'params': params}\n",
    "                 # Или просто пропустить фолд, но это исказит среднее\n",
    "                 continue # Пропускаем этот фолд\n",
    "\n",
    "            # Убедимся, что y_fold_val не пустой\n",
    "            if len(y_fold_val) == 0:\n",
    "                print(f\"Warning: Empty validation fold encountered for alpha={current_alpha}. Skipping fold.\")\n",
    "                continue\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        if not rmses: # Если все фолды были пропущены\n",
    "            print(f\"Warning: No valid RMSE scores calculated for alpha={current_alpha}. Returning large error.\")\n",
    "            avg_rmse = 1e10 # Возвращаем большое значение\n",
    "        else:\n",
    "            avg_rmse = np.mean(rmses)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during cross-validation for alpha={current_alpha}: {e}\")\n",
    "        avg_rmse = 1e10 # Возвращаем большое значение при ошибке\n",
    "\n",
    "    # Проверка на NaN или inf в итоговом avg_rmse\n",
    "    if not np.isfinite(avg_rmse):\n",
    "        avg_rmse = 1e10\n",
    "\n",
    "    # Возвращаем словарь, ожидаемый hyperopt\n",
    "    return {'loss': avg_rmse, 'status': STATUS_OK, 'params': params}\n",
    "\n",
    "# 3. Запускаем оптимизацию hyperopt\n",
    "print(f\"Запуск hyperopt для подбора alpha (max_evals={MAX_EVALS_HYPEROPT})...\")\n",
    "trials_ridge = Trials() # Объект для хранения истории поиска\n",
    "\n",
    "# Установка random seed для воспроизводимости hyperopt\n",
    "# Используй один из вариантов в зависимости от версии Python/numpy\n",
    "try:\n",
    "    rstate = np.random.default_rng(random_seed)\n",
    "except AttributeError:\n",
    "    rstate = np.random.RandomState(random_seed)\n",
    "\n",
    "\n",
    "best_params_ridge = fmin(\n",
    "    fn=objective_ridge,       # Наша целевая функция\n",
    "    space=space_ridge,        # Пространство поиска параметров\n",
    "    algo=tpe.suggest,         # Алгоритм оптимизации TPE\n",
    "    max_evals=MAX_EVALS_HYPEROPT, # Количество итераций\n",
    "    trials=trials_ridge,      # Для логирования\n",
    "    rstate=rstate             # Генератор случайных чисел для воспроизводимости\n",
    ")\n",
    "\n",
    "# Извлекаем лучший результат из trials (лучший loss = RMSE на CV)\n",
    "best_cv_rmse = trials_ridge.best_trial['result']['loss']\n",
    "# fmin возвращает только значения параметров, не их имена, восстанавливаем полный словарь\n",
    "best_final_params_ridge = {'alpha': best_params_ridge['alpha']}\n",
    "\n",
    "print(f\"\\nЛучшее найденное значение alpha для Ridge: {best_final_params_ridge['alpha']:.6f}\") # Выводим точнее\n",
    "print(f\"Лучший RMSE на кросс-валидации: {best_cv_rmse:.4f}\")\n",
    "\n",
    "# 4. Обучаем финальную модель Ridge с лучшими найденными параметрами\n",
    "print(\"\\nОбучение финальной модели Ridge на всем X_train_m...\")\n",
    "final_ridge_model = Ridge(**best_final_params_ridge) # Используем двойную звездочку для распаковки словаря\n",
    "final_ridge_model.fit(X_train_m, y_train)\n",
    "print(\"Финальная модель обучена.\")\n",
    "\n",
    "# 5. Генерация рекурсивного прогноза (используя final_ridge_model)\n",
    "print(\"\\nГенерация рекурсивного прогноза...\")\n",
    "initial_history_ridge = y_train.copy()\n",
    "forecast_ridge_recursive = recursive_predict(\n",
    "    model=final_ridge_model, # <<<--- Используем финальную модель\n",
    "    initial_history_series=initial_history_ridge,\n",
    "    n_steps=test_months,\n",
    "    feature_calculator=calculate_features_for_step,\n",
    "    feature_order=feature_order,\n",
    "    scaler=scaler # Передаем scaler, если он нужен для прогноза\n",
    ")\n",
    "# Обновляем словарь прогнозов с новым именем модели\n",
    "if model_name_ridge in recursive_forecasts: del recursive_forecasts[model_name_ridge] # Удаляем старый прогноз Ridge\n",
    "recursive_forecasts[model_name_ridge] = forecast_ridge_recursive # Добавляем новый\n",
    "print(f\"Прогноз {model_name_ridge} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "# 6. Оценка RMSE (код остается почти тем же, но использует новые прогнозы)\n",
    "# ... (код проверки длин y_test_eval, forecast_ridge_eval) ...\n",
    "if len(forecast_ridge_recursive) != len(y_test):\n",
    "     min_len = min(len(forecast_ridge_recursive), len(y_test))\n",
    "     print(f\"Warning: Length mismatch in recursive forecast ({len(forecast_ridge_recursive)}) vs y_test ({len(y_test)}). Using length {min_len}.\")\n",
    "     y_test_eval = y_test[:min_len]; forecast_ridge_eval = forecast_ridge_recursive[:min_len]\n",
    "else:\n",
    "     y_test_eval = y_test; forecast_ridge_eval = forecast_ridge_recursive\n",
    "\n",
    "overall_rmse_ridge_recursive = np.sqrt(mean_squared_error(y_test_eval, forecast_ridge_eval))\n",
    "print(f\"\\nОбщий RMSE на тесте для {model_name_ridge}: {overall_rmse_ridge_recursive:.4f}\")\n",
    "\n",
    "# 7. Обновление таблиц результатов (код остается тем же, но с новым model_name_ridge)\n",
    "# Удаляем старые результаты Ridge перед добавлением новых\n",
    "result_rmse = result_rmse[~result_rmse['method'].str.contains('Ridge', case=False)]\n",
    "df_horizon_rmse = df_horizon_rmse[~df_horizon_rmse['method'].str.contains('Ridge', case=False)]\n",
    "\n",
    "result_ridge_entry = {'method': model_name_ridge, 'rmse': overall_rmse_ridge_recursive}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_ridge_entry])], ignore_index=True)\n",
    "\n",
    "print(\"RMSE по горизонтам:\")\n",
    "horizon_results_list_ridge_rec = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(forecast_ridge_eval): # Используем длину фактического прогноза\n",
    "        forecast_h_step = forecast_ridge_eval[:h]\n",
    "        actual_h_step = y_test_eval[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h_step, forecast_h_step))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "        horizon_results_list_ridge_rec.append({'method': model_name_ridge, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse_ridge_rec = pd.DataFrame(horizon_results_list_ridge_rec)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_ridge_rec], ignore_index=True)\n",
    "print(\"Результаты RMSE по горизонтам добавлены/обновлены.\")\n",
    "\n",
    "# 8. График прогноза (код остается тем же, но с новым model_name_ridge и прогнозами)\n",
    "# ... (код графика) ...\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(y_test_eval.index, y_test_eval, label='Тестовая выборка (реальные)', color='orange', linewidth=2) # Используем y_test_eval\n",
    "forecast_ridge_series = pd.Series(forecast_ridge_eval, index=y_test_eval.index[:len(forecast_ridge_eval)])\n",
    "plt.plot(forecast_ridge_series.index, forecast_ridge_series, label=f'Прогноз {model_name_ridge}', color='green', linestyle='--')\n",
    "# Добавляем ARIMA для сравнения\n",
    "forecast_arima_series_plot = pd.Series(forecast_arima, index=y_test_eval.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series_plot.index, forecast_arima_series_plot, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_ridge}')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 9. График RMSE vs Горизонт (код остается тем же, но с новым model_name_ridge)\n",
    "# ... (код графика) ...\n",
    "if not df_horizon_rmse_ridge_rec.empty:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_horizon_rmse_ridge_rec['horizon'], df_horizon_rmse_ridge_rec['rmse'], marker='o', linestyle='-')\n",
    "    plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_ridge}')\n",
    "    plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "    plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "else:\n",
    "     print(f\"Нет данных для построения графика RMSE vs Горизонт для {model_name_ridge}\")\n",
    "\n",
    "\n",
    "print(f\"--- Анализ {model_name_ridge} завершен ---\")\n",
    "\n",
    "# 10. Вывод итоговых таблиц (код остается тем же)\n",
    "# ... (код вывода таблиц) ...\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_current_ridge_ho = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "current_order_ridge_ho = result_rmse.sort_values(by='rmse')['method'].tolist()\n",
    "for method in current_order_ridge_ho:\n",
    "     if method not in pivot_table_current_ridge_ho.columns: pivot_table_current_ridge_ho[method] = np.nan\n",
    "if model_name_ridge not in current_order_ridge_ho: current_order_ridge_ho.append(model_name_ridge)\n",
    "try:\n",
    "    print(pivot_table_current_ridge_ho[current_order_ridge_ho].round(4))\n",
    "except KeyError as e:\n",
    "     print(f\"Ошибка при сортировке колонок для вывода RMSE по горизонтам: {e}. Вывод как есть:\")\n",
    "     print(pivot_table_current_ridge_ho.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AvW4Xyan4xh"
   },
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3825,
     "status": "ok",
     "timestamp": 1746800584061,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "IKvyWgzan769",
    "outputId": "3da87e46-52ef-4229-abbc-d3a492ee7499"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 8: Модель Lasso (Обучение с hyperopt + Рекурсивный Прогноз) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "# Убираем GridSearchCV, добавляем hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Убедимся, что tscv определен\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# X_train_m, y_train - масштабированные DataFrame и Series\n",
    "# X_test_m, y_test - для теста\n",
    "# tscv - настроенный TimeSeriesSplit\n",
    "# scaler - обученный MinMaxScaler\n",
    "# calculate_features_for_step, feature_order, test_months, horizons_to_evaluate\n",
    "# result_rmse, df_horizon_rmse, recursive_forecasts\n",
    "# plot_start_date, forecast_arima\n",
    "# train_values, test_values\n",
    "# random_seed\n",
    "# recursive_predict\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "# --- Дополнительные настройки ---\n",
    "model_name_lasso = \"Lasso_Recursive\" # <<<--- СОХРАНЯЕМ ИМЯ\n",
    "MAX_EVALS_HYPEROPT_LASSO = 50 # Количество итераций для hyperopt Lasso (можно изменить)\n",
    "LASSO_MAX_ITER = 10000 # Увеличиваем итерации для сходимости Lasso\n",
    "# --- Конец Дополнительных настроек ---\n",
    "\n",
    "print(f\"\\n--- Обучение и Прогнозирование: {model_name_lasso} ---\")\n",
    "\n",
    "# 1. Определяем пространство поиска для hyperopt Lasso\n",
    "#    Используем loguniform от 1e-5 до 1.0.\n",
    "space_lasso = {\n",
    "    # np.log(1e-5) ~ -11.5, np.log(1.0) = 0\n",
    "    'alpha': hp.loguniform('alpha', np.log(0.00001), np.log(1.0))\n",
    "}\n",
    "print(f\"Пространство поиска alpha для Lasso: от {np.exp(np.log(0.00001)):.1E} до {np.exp(np.log(1.0)):.1f} (loguniform)\")\n",
    "\n",
    "# 2. Определяем целевую функцию (objective) для hyperopt Lasso\n",
    "def objective_lasso(params):\n",
    "    \"\"\"\n",
    "    Целевая функция для hyperopt. Обучает Lasso с заданным alpha\n",
    "    и оценивает его с помощью TimeSeriesSplit кросс-валидации.\n",
    "    Возвращает средний RMSE по фолдам.\n",
    "    \"\"\"\n",
    "    current_alpha = params['alpha']\n",
    "\n",
    "    # Увеличиваем max_iter для Lasso\n",
    "    # Можно добавить `tol` для контроля точности, если модель долго сходится\n",
    "    model = Lasso(alpha=current_alpha, max_iter=LASSO_MAX_ITER, tol=0.001, random_state=random_seed)\n",
    "\n",
    "    rmses = []\n",
    "    try:\n",
    "        for train_idx, val_idx in tscv.split(X_train_m): # X_train_m - масштабированные признаки\n",
    "            X_fold_train, X_fold_val = X_train_m.iloc[train_idx], X_train_m.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            preds = model.predict(X_fold_val)\n",
    "\n",
    "            if not np.all(np.isfinite(preds)) or not np.all(np.isfinite(y_fold_val.values)):\n",
    "                 # print(f\"Warning: Non-finite values found for alpha={current_alpha:.6f}. Skipping fold.\") # Можно раскомментировать для отладки\n",
    "                 continue\n",
    "\n",
    "            if len(y_fold_val) == 0:\n",
    "                 # print(f\"Warning: Empty validation fold for alpha={current_alpha:.6f}. Skipping fold.\")\n",
    "                 continue\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        if not rmses:\n",
    "            # print(f\"Warning: No valid RMSE scores for alpha={current_alpha:.6f}. Returning large error.\")\n",
    "            avg_rmse = 1e10\n",
    "        else:\n",
    "            avg_rmse = np.mean(rmses)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error during CV for alpha={current_alpha:.6f}: {e}\") # Можно раскомментировать для отладки\n",
    "        avg_rmse = 1e10 # Возвращаем большое значение при ошибке\n",
    "\n",
    "    if not np.isfinite(avg_rmse):\n",
    "        avg_rmse = 1e10\n",
    "\n",
    "    return {'loss': avg_rmse, 'status': STATUS_OK, 'params': params}\n",
    "\n",
    "# 3. Запускаем оптимизацию hyperopt\n",
    "print(f\"Запуск hyperopt для подбора alpha Lasso (max_evals={MAX_EVALS_HYPEROPT_LASSO})...\")\n",
    "trials_lasso = Trials()\n",
    "\n",
    "# Установка random seed для воспроизводимости hyperopt\n",
    "try:\n",
    "    rstate_lasso = np.random.default_rng(random_seed)\n",
    "except AttributeError:\n",
    "    rstate_lasso = np.random.RandomState(random_seed)\n",
    "\n",
    "best_params_lasso = fmin(\n",
    "    fn=objective_lasso,\n",
    "    space=space_lasso,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=MAX_EVALS_HYPEROPT_LASSO,\n",
    "    trials=trials_lasso,\n",
    "    rstate=rstate_lasso,\n",
    "    show_progressbar=True # Показываем прогресс\n",
    ")\n",
    "\n",
    "# Извлекаем лучший результат из trials\n",
    "try:\n",
    "    best_cv_rmse_lasso = trials_lasso.best_trial['result']['loss']\n",
    "    # fmin возвращает только значения параметров, не их имена\n",
    "    best_final_params_lasso = {'alpha': best_params_lasso['alpha']}\n",
    "    print(f\"\\nЛучшее найденное значение alpha для Lasso: {best_final_params_lasso['alpha']:.6f}\")\n",
    "    print(f\"Лучший RMSE на кросс-валидации: {best_cv_rmse_lasso:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nНе удалось извлечь лучший результат из hyperopt trials: {e}\")\n",
    "    print(\"Возможно, все итерации завершились с ошибкой. Проверьте objective функцию.\")\n",
    "    # В этом случае прерываем, так как нет лучших параметров\n",
    "    raise SystemExit(\"Прерывание из-за ошибки в hyperopt.\")\n",
    "\n",
    "\n",
    "# 4. Обучаем финальную модель Lasso с лучшими найденными параметрами\n",
    "print(\"\\nОбучение финальной модели Lasso на всем X_train_m...\")\n",
    "final_lasso_model = Lasso(**best_final_params_lasso, max_iter=LASSO_MAX_ITER, tol=0.001, random_state=random_seed)\n",
    "final_lasso_model.fit(X_train_m, y_train)\n",
    "\n",
    "# Выводим кол-во отобранных признаков финальной моделью\n",
    "n_features_selected = np.sum(final_lasso_model.coef_ != 0)\n",
    "print(f\"Количество отобранных признаков финальной моделью: {n_features_selected} из {X_train_m.shape[1]}\")\n",
    "print(\"Финальная модель обучена.\")\n",
    "\n",
    "# 5. Генерация рекурсивного прогноза (используя final_lasso_model)\n",
    "print(\"\\nГенерация рекурсивного прогноза...\")\n",
    "initial_history_lasso = y_train.copy()\n",
    "forecast_lasso_recursive = recursive_predict(\n",
    "    model=final_lasso_model, # <<<--- Используем финальную модель\n",
    "    initial_history_series=initial_history_lasso,\n",
    "    n_steps=test_months,\n",
    "    feature_calculator=calculate_features_for_step,\n",
    "    feature_order=feature_order,\n",
    "    scaler=scaler # Передаем scaler\n",
    ")\n",
    "# Обновляем словарь прогнозов, сохраняя имя модели\n",
    "if model_name_lasso in recursive_forecasts: del recursive_forecasts[model_name_lasso]\n",
    "recursive_forecasts[model_name_lasso] = forecast_lasso_recursive\n",
    "print(f\"Прогноз {model_name_lasso} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "# 6. Оценка RMSE (код остается тем же)\n",
    "# ... (код проверки длин y_test_eval, forecast_lasso_eval) ...\n",
    "if len(forecast_lasso_recursive) != len(y_test):\n",
    "     min_len = min(len(forecast_lasso_recursive), len(y_test))\n",
    "     print(f\"Warning: Length mismatch in recursive forecast ({len(forecast_lasso_recursive)}) vs y_test ({len(y_test)}). Using length {min_len}.\")\n",
    "     y_test_eval = y_test[:min_len]; forecast_lasso_eval = forecast_lasso_recursive[:min_len]\n",
    "else:\n",
    "     y_test_eval = y_test; forecast_lasso_eval = forecast_lasso_recursive\n",
    "\n",
    "overall_rmse_lasso_recursive = np.sqrt(mean_squared_error(y_test_eval, forecast_lasso_eval))\n",
    "print(f\"\\nОбщий RMSE на тесте для {model_name_lasso}: {overall_rmse_lasso_recursive:.4f}\")\n",
    "\n",
    "# 7. Обновление таблиц результатов (код остается тем же)\n",
    "# Удаляем старые результаты Lasso перед добавлением новых\n",
    "result_rmse = result_rmse[~result_rmse['method'].str.contains('Lasso', case=False)]\n",
    "df_horizon_rmse = df_horizon_rmse[~df_horizon_rmse['method'].str.contains('Lasso', case=False)]\n",
    "\n",
    "result_lasso_entry = {'method': model_name_lasso, 'rmse': overall_rmse_lasso_recursive}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_lasso_entry])], ignore_index=True)\n",
    "\n",
    "print(\"RMSE по горизонтам:\")\n",
    "horizon_results_list_lasso_rec = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(forecast_lasso_eval): # Используем длину фактического прогноза\n",
    "        forecast_h_step = forecast_lasso_eval[:h]\n",
    "        actual_h_step = y_test_eval[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h_step, forecast_h_step))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "        horizon_results_list_lasso_rec.append({'method': model_name_lasso, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse_lasso_rec = pd.DataFrame(horizon_results_list_lasso_rec)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_lasso_rec], ignore_index=True)\n",
    "print(\"Результаты RMSE по горизонтам добавлены/обновлены.\")\n",
    "\n",
    "# 4. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2)\n",
    "forecast_lasso_series = pd.Series(forecast_lasso_eval, index=test.index[:len(forecast_lasso_eval)])\n",
    "plt.plot(forecast_lasso_series.index, forecast_lasso_series, label=f'Прогноз {model_name_lasso}', color='purple', linestyle='--')\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_lasso} (Рекурсивный)')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. График RMSE vs Горизонт (только для этой модели)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_horizon_rmse_lasso_rec['horizon'], df_horizon_rmse_lasso_rec['rmse'], marker='o', linestyle='-')\n",
    "plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_lasso}')\n",
    "plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "\n",
    "print(f\"--- Анализ {model_name_lasso} завершен ---\")\n",
    "\n",
    "# 6. Вывод итоговых таблиц (для сравнения с предыдущими)\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_current = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "current_order = result_rmse['method'].tolist()\n",
    "for method in current_order:\n",
    "     if method not in pivot_table_current.columns: pivot_table_current[method] = np.nan\n",
    "print(pivot_table_current[current_order].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1272,
     "status": "ok",
     "timestamp": 1746801360964,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "8EaKhLcqbcP3",
    "outputId": "a0ffc3f6-5850-4e5e-b862-9b334359b34e"
   },
   "outputs": [],
   "source": [
    "# 4. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2)\n",
    "forecast_lasso_series = pd.Series(forecast_lasso_eval, index=test.index[:len(forecast_lasso_eval)])\n",
    "plt.plot(forecast_lasso_series.index, forecast_lasso_series, label=f'Прогноз {model_name_lasso}', color='purple', linestyle='--')\n",
    "forecast_ridge_series = pd.Series(forecast_ridge_eval, index=y_test_eval.index[:len(forecast_ridge_eval)])\n",
    "plt.plot(forecast_ridge_series.index, forecast_ridge_series, label=f'Прогноз {model_name_ridge}', color='green', linestyle='--')\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью Ridge и Lasso (Рекурсивный)')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grlQXLbgbc4K"
   },
   "source": [
    "#RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 232584,
     "status": "ok",
     "timestamp": 1746802303507,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "PtwBnw0EqAu-",
    "outputId": "f774fee1-aac8-4987-98e6-b64faab02c27"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 9: Модель Random Forest (Обучение с hyperopt + Рекурсивный Прогноз) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Убираем GridSearchCV, добавляем hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Убедимся, что tscv определен\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# X_train, y_train - НЕмасштабированные DataFrame и Series\n",
    "# X_test, y_test - для теста\n",
    "# tscv - настроенный TimeSeriesSplit\n",
    "# calculate_features_for_step, feature_order, test_months, horizons_to_evaluate\n",
    "# result_rmse, df_horizon_rmse, recursive_forecasts\n",
    "# plot_start_date, forecast_arima\n",
    "# train_values, test_values\n",
    "# random_seed\n",
    "# recursive_predict\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "# --- Дополнительные настройки ---\n",
    "model_name_rf = \"RF_Recursive\" # <<<--- СОХРАНЯЕМ ИМЯ\n",
    "MAX_EVALS_HYPEROPT_RF = 50 # Количество итераций для hyperopt RF (можно увеличить до 75-100, если время позволяет)\n",
    "# --- Конец Дополнительных настроек ---\n",
    "\n",
    "print(f\"\\n--- Обучение и Прогнозирование: {model_name_rf} ---\")\n",
    "\n",
    "# 1. Определяем пространство поиска для hyperopt Random Forest\n",
    "#    Определяем диапазоны и типы распределений для каждого параметра\n",
    "space_rf = {\n",
    "    # hp.quniform(label, low, high, q) - выбирает значение round(uniform(low, high) / q) * q\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 300, 25), # Шаг 25, от 100 до 300\n",
    "    # hp.choice(label, options) - выбирает один из списка options\n",
    "    'max_depth': hp.choice('max_depth', [4, 6, 8, 10, 12, None]), # Включаем None и значения вокруг 6\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 0.6, 0.7, 0.8, 0.9]), # Включаем 'sqrt' и доли вокруг 0.7\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1), # Целые от 2 до 10\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 12, 2),    # Целые от 1 до 6\n",
    "    # 'bootstrap': hp.choice('bootstrap', [True, False]) # Можно добавить, если нужно\n",
    "}\n",
    "print(f\"Пространство поиска для Random Forest: {space_rf}\")\n",
    "\n",
    "# 2. Определяем целевую функцию (objective) для hyperopt RF\n",
    "def objective_rf(params):\n",
    "    \"\"\"\n",
    "    Целевая функция для hyperopt. Обучает RandomForestRegressor с заданными\n",
    "    параметрами и оценивает его с помощью TimeSeriesSplit кросс-валидации.\n",
    "    Возвращает средний RMSE по фолдам.\n",
    "    \"\"\"\n",
    "    # Преобразуем параметры из hyperopt в нужный формат (особенно целые числа)\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    # max_depth может быть None, hp.choice вернет его как есть\n",
    "    # max_features может быть строкой или float, hp.choice вернет как есть\n",
    "    params['min_samples_split'] = int(params['min_samples_split'])\n",
    "    params['min_samples_leaf'] = int(params['min_samples_leaf'])\n",
    "\n",
    "    # Создаем модель с текущими параметрами + важные фиксированные параметры\n",
    "    model = RandomForestRegressor(\n",
    "        **params,                 # Распаковываем параметры из hyperopt\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1                 # Используем все ядра CPU\n",
    "    )\n",
    "\n",
    "    rmses = []\n",
    "    try:\n",
    "        # Используем НЕмасштабированные X_train\n",
    "        for train_idx, val_idx in tscv.split(X_train):\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            preds = model.predict(X_fold_val)\n",
    "\n",
    "            if not np.all(np.isfinite(preds)) or not np.all(np.isfinite(y_fold_val.values)):\n",
    "                 continue\n",
    "\n",
    "            if len(y_fold_val) == 0:\n",
    "                 continue\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        if not rmses:\n",
    "            avg_rmse = 1e10\n",
    "        else:\n",
    "            avg_rmse = np.mean(rmses)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error during CV for params={params}: {e}\") # Отладка\n",
    "        avg_rmse = 1e10\n",
    "\n",
    "    if not np.isfinite(avg_rmse):\n",
    "        avg_rmse = 1e10\n",
    "\n",
    "    # Сохраняем параметры в trials для последующего анализа (не обязательно, но полезно)\n",
    "    # hyperopt автоматически сохраняет loss и status\n",
    "    # return {'loss': avg_rmse, 'status': STATUS_OK, 'params': params}\n",
    "    # Но можно вернуть только loss и status, т.к. fmin вернет лучшие параметры\n",
    "    return {'loss': avg_rmse, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "# 3. Запускаем оптимизацию hyperopt\n",
    "print(f\"Запуск hyperopt для подбора параметров Random Forest (max_evals={MAX_EVALS_HYPEROPT_RF})...\")\n",
    "trials_rf = Trials()\n",
    "\n",
    "try:\n",
    "    rstate_rf = np.random.default_rng(random_seed)\n",
    "except AttributeError:\n",
    "    rstate_rf = np.random.RandomState(random_seed)\n",
    "\n",
    "# fmin вернет словарь только с индексами/значениями из hp.choice или числовыми значениями\n",
    "best_params_raw = fmin(\n",
    "    fn=objective_rf,\n",
    "    space=space_rf,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=MAX_EVALS_HYPEROPT_RF,\n",
    "    trials=trials_rf,\n",
    "    rstate=rstate_rf,\n",
    "    show_progressbar=True\n",
    ")\n",
    "\n",
    "# Преобразуем результат fmin обратно в читаемые параметры, используя space\n",
    "# space_eval нужен для hp.choice, чтобы получить реальное значение (строку или None), а не индекс\n",
    "best_final_params_rf = space_eval(space_rf, best_params_raw)\n",
    "\n",
    "# Преобразуем числовые параметры к нужному типу (int)\n",
    "best_final_params_rf['n_estimators'] = int(best_final_params_rf['n_estimators'])\n",
    "best_final_params_rf['min_samples_split'] = int(best_final_params_rf['min_samples_split'])\n",
    "best_final_params_rf['min_samples_leaf'] = int(best_final_params_rf['min_samples_leaf'])\n",
    "# max_depth и max_features уже должны быть в правильном формате из space_eval\n",
    "\n",
    "# Получаем лучший CV RMSE из trials\n",
    "try:\n",
    "    best_cv_rmse_rf = trials_rf.best_trial['result']['loss']\n",
    "    print(f\"\\nЛучшие найденные параметры для Random Forest: {best_final_params_rf}\")\n",
    "    print(f\"Лучший RMSE на кросс-валидации: {best_cv_rmse_rf:.4f}\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nНе удалось извлечь лучший результат из hyperopt trials: {e}\")\n",
    "     print(f\"Найденные параметры (могут быть не лучшими): {best_final_params_rf}\")\n",
    "     # Прерываем, если не можем получить лучший результат\n",
    "     raise SystemExit(\"Прерывание из-за ошибки в hyperopt.\")\n",
    "\n",
    "\n",
    "# 4. Обучаем финальную модель Random Forest с лучшими найденными параметрами\n",
    "print(\"\\nОбучение финальной модели Random Forest на всем X_train...\")\n",
    "final_rf_model = RandomForestRegressor(\n",
    "    **best_final_params_rf,\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1\n",
    "    # bootstrap=True # Если не было в space\n",
    ")\n",
    "# Обучаем на НЕмасштабированных X_train\n",
    "final_rf_model.fit(X_train, y_train)\n",
    "print(\"Финальная модель обучена.\")\n",
    "\n",
    "# 5. Генерация рекурсивного прогноза (используя final_rf_model)\n",
    "print(\"\\nГенерация рекурсивного прогноза...\")\n",
    "initial_history_rf = y_train.copy()\n",
    "forecast_rf_recursive = recursive_predict(\n",
    "    model=final_rf_model, # <<<--- Используем финальную модель RF\n",
    "    initial_history_series=initial_history_rf,\n",
    "    n_steps=test_months,\n",
    "    feature_calculator=calculate_features_for_step,\n",
    "    feature_order=feature_order,\n",
    "    scaler=None # RF обучался на немасштабированных признаках\n",
    ")\n",
    "# Обновляем словарь прогнозов, сохраняя имя модели\n",
    "if model_name_rf in recursive_forecasts: del recursive_forecasts[model_name_rf]\n",
    "recursive_forecasts[model_name_rf] = forecast_rf_recursive\n",
    "print(f\"Прогноз {model_name_rf} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "# 3. Оценка RMSE\n",
    "# Проверка длин\n",
    "if len(forecast_rf_recursive) != len(y_test):\n",
    "     min_len = min(len(forecast_rf_recursive), len(y_test));\n",
    "     y_test_eval = y_test[:min_len]; forecast_rf_eval = forecast_rf_recursive[:min_len]\n",
    "else:\n",
    "     y_test_eval = y_test; forecast_rf_eval = forecast_rf_recursive\n",
    "\n",
    "overall_rmse_rf_recursive = np.sqrt(mean_squared_error(y_test_eval, forecast_rf_eval))\n",
    "print(f\"\\nОбщий RMSE на тесте для {model_name_rf}: {overall_rmse_rf_recursive:.4f}\")\n",
    "\n",
    "# Добавляем/Обновляем общий RMSE\n",
    "result_rmse = result_rmse[~result_rmse['method'].isin(['Random Forest', model_name_rf])]\n",
    "result_rf_rec_entry = {'method': model_name_rf, 'rmse': overall_rmse_rf_recursive}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_rf_rec_entry])], ignore_index=True)\n",
    "\n",
    "# Расчет и добавление RMSE по горизонтам\n",
    "print(\"RMSE по горизонтам:\")\n",
    "df_horizon_rmse = df_horizon_rmse[~df_horizon_rmse['method'].isin(['Random Forest', model_name_rf])]\n",
    "horizon_results_list_rf_rec = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(y_test_eval):\n",
    "        forecast_h = forecast_rf_eval[:h]\n",
    "        actual_h = y_test_eval[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h, forecast_h))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "        horizon_results_list_rf_rec.append({'method': model_name_rf, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse_rf_rec = pd.DataFrame(horizon_results_list_rf_rec)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_rf_rec], ignore_index=True)\n",
    "print(\"Результаты RMSE по горизонтам добавлены/обновлены.\")\n",
    "\n",
    "# 4. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2)\n",
    "forecast_rf_series = pd.Series(forecast_rf_eval, index=test.index[:len(forecast_rf_eval)])\n",
    "plt.plot(forecast_rf_series.index, forecast_rf_series, label=f'Прогноз {model_name_rf}', color='teal', linestyle='--')\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_rf} (Рекурсивный)')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. График RMSE vs Горизонт (только для этой модели)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_horizon_rmse_rf_rec['horizon'], df_horizon_rmse_rf_rec['rmse'], marker='o', linestyle='-')\n",
    "plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_rf}')\n",
    "plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "\n",
    "print(f\"--- Анализ {model_name_rf} завершен ---\")\n",
    "\n",
    "# 6. Вывод итоговых таблиц (для сравнения с предыдущими)\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_current = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "current_order = result_rmse.sort_values(by='rmse')['method'].tolist()\n",
    "# Добавляем и сортируем колонки\n",
    "for method in current_order:\n",
    "     if method not in pivot_table_current.columns: pivot_table_current[method] = np.nan\n",
    "# Убедимся, что новая модель есть в current_order, если вдруг result_rmse не успел обновиться\n",
    "if model_name_rf not in current_order: current_order.append(model_name_rf)\n",
    "# Попытаемся вывести в отсортированном порядке, но если колонки нет - выведем как есть\n",
    "try:\n",
    "    print(pivot_table_current[current_order].round(4))\n",
    "except KeyError:\n",
    "     print(\"Не удалось отсортировать колонки, вывод как есть:\")\n",
    "     print(pivot_table_current.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRuM_yHQsdiS"
   },
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 91305,
     "status": "ok",
     "timestamp": 1746802394817,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "VeIqEgeKsfev",
    "outputId": "a710525e-b988-4bac-ae53-83a7508e44c6"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 10: Модель XGBoost (Обучение с hyperopt + Рекурсивный Прогноз) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "# Убираем GridSearchCV, добавляем hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Убедимся, что tscv определен\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# X_train, y_train - НЕмасштабированные DataFrame и Series\n",
    "# X_test, y_test - для теста\n",
    "# tscv - настроенный TimeSeriesSplit\n",
    "# calculate_features_for_step, feature_order, test_months, horizons_to_evaluate\n",
    "# result_rmse, df_horizon_rmse, recursive_forecasts\n",
    "# plot_start_date, forecast_arima\n",
    "# train_values, test_values\n",
    "# random_seed\n",
    "# recursive_predict\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "# --- Дополнительные настройки ---\n",
    "model_name_xgb = \"XGB_Recursive\" # <<<--- СОХРАНЯЕМ ИМЯ\n",
    "MAX_EVALS_HYPEROPT_XGB = 75 # Количество итераций (можно начать с 50-75 и увеличить при необходимости)\n",
    "# --- Конец Дополнительных настроек ---\n",
    "\n",
    "print(f\"\\n--- Обучение и Прогнозирование: {model_name_xgb} ---\")\n",
    "\n",
    "# 1. Определяем пространство поиска для hyperopt XGBoost\n",
    "space_xgb = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 400, 25),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 4, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 0.5),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', np.log(0.001), np.log(1.0)),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', np.log(0.1), np.log(10.0))\n",
    "}\n",
    "print(f\"Пространство поиска для XGBoost: {space_xgb}\")\n",
    "\n",
    "\n",
    "# 2. Определяем целевую функцию (objective) для hyperopt XGBoost\n",
    "def objective_xgb(params):\n",
    "    \"\"\"\n",
    "    Целевая функция для hyperopt. Обучает XGBoost с заданными\n",
    "    параметрами и оценивает его с помощью TimeSeriesSplit кросс-валидации.\n",
    "    Возвращает средний RMSE по фолдам.\n",
    "    \"\"\"\n",
    "    # Преобразуем типы параметров\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "    # Создаем модель\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1, # Используем все ядра\n",
    "        **params # Распаковываем параметры из hyperopt\n",
    "    )\n",
    "\n",
    "    rmses = []\n",
    "    try:\n",
    "        # Используем НЕмасштабированные X_train\n",
    "        for train_idx, val_idx in tscv.split(X_train):\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train) # Можно добавить early_stopping_rounds здесь, если нужно\n",
    "            preds = model.predict(X_fold_val)\n",
    "\n",
    "            if not np.all(np.isfinite(preds)) or not np.all(np.isfinite(y_fold_val.values)):\n",
    "                 continue\n",
    "\n",
    "            if len(y_fold_val) == 0:\n",
    "                 continue\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        if not rmses:\n",
    "            avg_rmse = 1e10\n",
    "        else:\n",
    "            avg_rmse = np.mean(rmses)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error during CV for params={params}: {e}\") # Отладка\n",
    "        avg_rmse = 1e10\n",
    "\n",
    "    if not np.isfinite(avg_rmse):\n",
    "        avg_rmse = 1e10\n",
    "\n",
    "    return {'loss': avg_rmse, 'status': STATUS_OK }\n",
    "\n",
    "# 3. Запускаем оптимизацию hyperopt\n",
    "print(f\"Запуск hyperopt для подбора параметров XGBoost (max_evals={MAX_EVALS_HYPEROPT_XGB})...\")\n",
    "trials_xgb = Trials()\n",
    "\n",
    "try:\n",
    "    rstate_xgb = np.random.default_rng(random_seed)\n",
    "except AttributeError:\n",
    "    rstate_xgb = np.random.RandomState(random_seed)\n",
    "\n",
    "best_params_raw_xgb = fmin(\n",
    "    fn=objective_xgb,\n",
    "    space=space_xgb,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=MAX_EVALS_HYPEROPT_XGB,\n",
    "    trials=trials_xgb,\n",
    "    rstate=rstate_xgb,\n",
    "    show_progressbar=True\n",
    ")\n",
    "\n",
    "# Преобразуем результат fmin обратно в читаемые параметры\n",
    "best_final_params_xgb = space_eval(space_xgb, best_params_raw_xgb)\n",
    "\n",
    "# Преобразуем числовые параметры к нужному типу (int)\n",
    "best_final_params_xgb['n_estimators'] = int(best_final_params_xgb['n_estimators'])\n",
    "best_final_params_xgb['max_depth'] = int(best_final_params_xgb['max_depth'])\n",
    "\n",
    "# Получаем лучший CV RMSE из trials\n",
    "try:\n",
    "    best_cv_rmse_xgb = trials_xgb.best_trial['result']['loss']\n",
    "    print(f\"\\nЛучшие найденные параметры для XGBoost: {best_final_params_xgb}\")\n",
    "    print(f\"Лучший RMSE на кросс-валидации: {best_cv_rmse_xgb:.4f}\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nНе удалось извлечь лучший результат из hyperopt trials: {e}\")\n",
    "     print(f\"Найденные параметры (могут быть не лучшими): {best_final_params_xgb}\")\n",
    "     raise SystemExit(\"Прерывание из-за ошибки в hyperopt.\")\n",
    "\n",
    "\n",
    "# 4. Обучаем финальную модель XGBoost с лучшими найденными параметрами\n",
    "print(\"\\nОбучение финальной модели XGBoost на всем X_train...\")\n",
    "final_xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1,\n",
    "    **best_final_params_xgb\n",
    ")\n",
    "# Обучаем на НЕмасштабированных X_train\n",
    "final_xgb_model.fit(X_train, y_train)\n",
    "print(\"Финальная модель обучена.\")\n",
    "\n",
    "# 5. Генерация рекурсивного прогноза (используя final_xgb_model)\n",
    "print(\"\\nГенерация рекурсивного прогноза...\")\n",
    "initial_history_xgb = y_train.copy()\n",
    "forecast_xgb_recursive = recursive_predict(\n",
    "    model=final_xgb_model, # <<<--- Используем финальную модель XGB\n",
    "    initial_history_series=initial_history_xgb,\n",
    "    n_steps=test_months,\n",
    "    feature_calculator=calculate_features_for_step,\n",
    "    feature_order=feature_order,\n",
    "    scaler=None # XGBoost обучался на немасштабированных признаках\n",
    ")\n",
    "# Обновляем словарь прогнозов, сохраняя имя модели\n",
    "if model_name_xgb in recursive_forecasts: del recursive_forecasts[model_name_xgb]\n",
    "recursive_forecasts[model_name_xgb] = forecast_xgb_recursive\n",
    "print(f\"Прогноз {model_name_xgb} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "# 3. Оценка RMSE\n",
    "# Проверка длин\n",
    "if len(forecast_xgb_recursive) != len(y_test):\n",
    "     min_len = min(len(forecast_xgb_recursive), len(y_test));\n",
    "     y_test_eval = y_test[:min_len]; forecast_xgb_eval = forecast_xgb_recursive[:min_len]\n",
    "else:\n",
    "     y_test_eval = y_test; forecast_xgb_eval = forecast_xgb_recursive\n",
    "\n",
    "overall_rmse_xgb_recursive = np.sqrt(mean_squared_error(y_test_eval, forecast_xgb_eval))\n",
    "print(f\"\\nОбщий RMSE на тесте для {model_name_xgb}: {overall_rmse_xgb_recursive:.4f}\")\n",
    "\n",
    "# Добавляем/Обновляем общий RMSE\n",
    "result_rmse = result_rmse[~result_rmse['method'].isin(['XGBoost', model_name_xgb])]\n",
    "result_xgb_rec_entry = {'method': model_name_xgb, 'rmse': overall_rmse_xgb_recursive}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_xgb_rec_entry])], ignore_index=True)\n",
    "\n",
    "# Расчет и добавление RMSE по горизонтам\n",
    "print(\"RMSE по горизонтам:\")\n",
    "df_horizon_rmse = df_horizon_rmse[~df_horizon_rmse['method'].isin(['XGBoost', model_name_xgb])]\n",
    "horizon_results_list_xgb_rec = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(y_test_eval):\n",
    "        forecast_h = forecast_xgb_eval[:h]\n",
    "        actual_h = y_test_eval[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h, forecast_h))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "        horizon_results_list_xgb_rec.append({'method': model_name_xgb, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse_xgb_rec = pd.DataFrame(horizon_results_list_xgb_rec)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_xgb_rec], ignore_index=True)\n",
    "print(\"Результаты RMSE по горизонтам добавлены/обновлены.\")\n",
    "\n",
    "# 4. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2)\n",
    "forecast_xgb_series = pd.Series(forecast_xgb_eval, index=test.index[:len(forecast_xgb_eval)])\n",
    "plt.plot(forecast_xgb_series.index, forecast_xgb_series, label=f'Прогноз {model_name_xgb}', color='red', linestyle='--')\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_xgb} (Рекурсивный)')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. График RMSE vs Горизонт (только для этой модели)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_horizon_rmse_xgb_rec['horizon'], df_horizon_rmse_xgb_rec['rmse'], marker='o', linestyle='-')\n",
    "plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_xgb}')\n",
    "plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "\n",
    "print(f\"--- Анализ {model_name_xgb} завершен ---\")\n",
    "\n",
    "# 6. Вывод итоговых таблиц (для сравнения с предыдущими)\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_current = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "current_order = result_rmse.sort_values(by='rmse')['method'].tolist()\n",
    "# Добавляем и сортируем колонки\n",
    "for method in current_order:\n",
    "     if method not in pivot_table_current.columns: pivot_table_current[method] = np.nan\n",
    "if model_name_xgb not in current_order: current_order.append(model_name_xgb) # Добавляем новую модель в порядок\n",
    "try:\n",
    "    print(pivot_table_current[current_order].round(4))\n",
    "except KeyError as e:\n",
    "     print(f\"Ошибка при сортировке колонок: {e}. Вывод как есть:\")\n",
    "     print(pivot_table_current.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1746802395172,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "bM11eskRhMSH",
    "outputId": "67f28ecf-6507-4e1d-e1d6-864e4f37dac9"
   },
   "outputs": [],
   "source": [
    "# 4. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2)\n",
    "forecast_xgb_series = pd.Series(forecast_xgb_eval, index=test.index[:len(forecast_xgb_eval)])\n",
    "plt.plot(forecast_xgb_series.index, forecast_xgb_series, label=f'Прогноз {model_name_xgb}', color='red', linestyle='--')\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "forecast_rf_series = pd.Series(forecast_rf_eval, index=test.index[:len(forecast_rf_eval)])\n",
    "plt.plot(forecast_rf_series.index, forecast_rf_series, label=f'Прогноз {model_name_rf}', color='teal', linestyle='--')\n",
    "plt.title(f'Прогноз ИПЦ с помощью RF и XGB (Рекурсивный)')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRMIT6U9xZ24"
   },
   "source": [
    "# Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1746804974804,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "hnt2ctaJxa_9",
    "outputId": "bc2eabe6-546b-4176-e5e4-2c6277ca29bb"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 11: Бленд ARIMA + Деревья (Обновленный) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# recursive_forecasts: Словарь УЖЕ СОДЕРЖИТ 'ARIMA', 'RF_Recursive', 'XGB_Recursive'.\n",
    "# forecast_arima: Рекурсивный прогноз ARIMA(1,0,0) (numpy array)\n",
    "# result_rmse: DataFrame с общими RMSE этих моделей.\n",
    "# df_horizon_rmse: DataFrame с RMSE по горизонтам.\n",
    "# y_test, test_months, horizons_to_evaluate, history_points_to_show\n",
    "# y_train, test_ml.index\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "# --- 1. Сбор данных для блендинга (ARIMA, RF_R, XGB_R) ---\n",
    "model_names_for_blend_select = [\n",
    "    'ARIMA',\n",
    "    'RF_Recursive',\n",
    "    'XGB_Recursive'\n",
    "]\n",
    "model_name_blend_select = \"Blend_ARIMA_Trees\" # Имя финального бленда\n",
    "\n",
    "# Соберем прогнозы из основного словаря recursive_forecasts\n",
    "try:\n",
    "    if 'recursive_forecasts' not in locals(): raise NameError(\"Словарь recursive_forecasts не найден\")\n",
    "    # Заменяем 'ARIMA' в словаре на актуальный прогноз (на всякий случай)\n",
    "    recursive_forecasts['ARIMA'] = forecast_arima[:test_months]\n",
    "    missing_forecasts = [name for name in model_names_for_blend_select if name not in recursive_forecasts]\n",
    "    if missing_forecasts:\n",
    "        raise KeyError(f\"Отсутствуют прогнозы для: {', '.join(missing_forecasts)}\")\n",
    "    # Используем основной словарь recursive_forecasts\n",
    "    model_forecasts_select = {name: recursive_forecasts[name] for name in model_names_for_blend_select}\n",
    "except (NameError, KeyError) as e:\n",
    "    print(f\"Ошибка при сборе прогнозов для блендинга: {e}.\")\n",
    "    raise e\n",
    "\n",
    "# Извлечем ИХ общие RMSE из таблицы 'result_rmse'\n",
    "try:\n",
    "    model_rmses_select = result_rmse[result_rmse['method'].isin(model_names_for_blend_select)].set_index('method')['rmse']\n",
    "    if len(model_rmses_select) != len(model_names_for_blend_select):\n",
    "         missing_rmse = set(model_names_for_blend_select) - set(model_rmses_select.index)\n",
    "         raise ValueError(f\"Не все RMSE найдены. Отсутствуют: {missing_rmse}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при извлечении RMSE для блендинга: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(\"--- Расчет весов для блендинга (ARIMA + Деревья) ---\")\n",
    "print(\"RMSE моделей для блендинга:\")\n",
    "print(model_rmses_select)\n",
    "\n",
    "# Расчет весов\n",
    "inverse_rmses_select = 1 / model_rmses_select\n",
    "total_inverse_rmse_select = inverse_rmses_select.sum()\n",
    "weights_select = inverse_rmses_select / total_inverse_rmse_select\n",
    "print(\"\\nВеса моделей в бленде:\")\n",
    "print(weights_select.round(4))\n",
    "print(f\"\\nСумма весов: {weights_select.sum():.4f}\")\n",
    "\n",
    "# --- 2. Создание комбинированного прогноза (Blend_ARIMA_Trees) ---\n",
    "print(f\"\\n--- Создание и оценка {model_name_blend_select} прогноза ---\")\n",
    "forecast_blend_select_recursive = np.zeros(len(y_test), dtype=float)\n",
    "valid_models_in_blend_select = 0\n",
    "\n",
    "for method_name, forecast_array in model_forecasts_select.items():\n",
    "    # Используем forecast_array напрямую из словаря, т.к. обновили 'ARIMA' в recursive_forecasts\n",
    "    current_forecast = forecast_array\n",
    "\n",
    "    if len(current_forecast) == len(y_test):\n",
    "        forecast_blend_select_recursive += current_forecast * weights_select[method_name]\n",
    "        valid_models_in_blend_select += 1\n",
    "    else:\n",
    "        print(f\"Предупреждение: Длина прогноза {method_name} ({len(current_forecast)}) не совпадает с y_test ({len(y_test)}).\")\n",
    "\n",
    "\n",
    "if valid_models_in_blend_select != len(model_names_for_blend_select):\n",
    "    print(f\"ВНИМАНИЕ: Не все модели ({valid_models_in_blend_select} из {len(model_names_for_blend_select)}) были использованы в бленде из-за длины.\")\n",
    "    if valid_models_in_blend_select == 0:\n",
    "        raise ValueError(\"Невозможно создать бленд.\")\n",
    "\n",
    "\n",
    "recursive_forecasts[model_name_blend_select] = forecast_blend_select_recursive[:test_months]\n",
    "print(f\"Прогноз {model_name_blend_select} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "\n",
    "# --- 3. Оценка Blend_ARIMA_Trees ---\n",
    "# Проверка длин\n",
    "if len(forecast_blend_select_recursive) != len(y_test):\n",
    "     min_len = min(len(forecast_blend_select_recursive), len(y_test));\n",
    "     y_test_eval = y_test[:min_len]; forecast_blend_select_eval = forecast_blend_select_recursive[:min_len]\n",
    "else:\n",
    "     y_test_eval = y_test; forecast_blend_select_eval = forecast_blend_select_recursive\n",
    "\n",
    "overall_rmse_blend_select_recursive = np.sqrt(mean_squared_error(y_test_eval, forecast_blend_select_eval))\n",
    "print(f\"Общий RMSE на тесте для {model_name_blend_select}: {overall_rmse_blend_select_recursive:.4f}\")\n",
    "\n",
    "# --- Обновление таблиц результатов ---\n",
    "# Удаляем старые бленды, если были\n",
    "result_rmse = result_rmse[~result_rmse['method'].isin(['Blend_ARIMA_Trees', 'Blend_Trees_Recursive', 'Blend_ML_Recursive', 'Blend'])]\n",
    "df_horizon_rmse = df_horizon_rmse[~df_horizon_rmse['method'].isin(['Blend_ARIMA_Trees', 'Blend_Trees_Recursive', 'Blend_ML_Recursive', 'Blend'])]\n",
    "\n",
    "# Добавляем новый общий RMSE\n",
    "result_blend_select_entry = {'method': model_name_blend_select, 'rmse': overall_rmse_blend_select_recursive}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_blend_select_entry])], ignore_index=True)\n",
    "\n",
    "print(\"\\nОбновленная таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "\n",
    "# --- Расчет RMSE по горизонтам для Blend_ARIMA_Trees ---\n",
    "print(f\"\\n--- Расчет RMSE по горизонтам для {model_name_blend_select} ---\")\n",
    "horizon_results_list_blend_select = []\n",
    "\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(y_test_eval):\n",
    "        forecast_h = forecast_blend_select_eval[:h]\n",
    "        actual_h = y_test_eval[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h, forecast_h))\n",
    "        print(f\"RMSE для горизонта 1-{h} мес.: {rmse_h:.4f}\")\n",
    "        horizon_results_list_blend_select.append({'method': model_name_blend_select, 'horizon': h, 'rmse': rmse_h})\n",
    "\n",
    "df_horizon_rmse_blend_select = pd.DataFrame(horizon_results_list_blend_select)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_blend_select], ignore_index=True)\n",
    "\n",
    "print(\"\\nОбновленная таблица RMSE по горизонтам:\")\n",
    "relevant_methods_select = result_rmse['method'].tolist() # Все текущие модели\n",
    "pivot_table_select = df_horizon_rmse[df_horizon_rmse['method'].isin(relevant_methods_select)].pivot(index='horizon', columns='method', values='rmse')\n",
    "for method in relevant_methods_select:\n",
    "     if method not in pivot_table_select.columns: pivot_table_select[method] = np.nan\n",
    "current_rmse_order_select = result_rmse.sort_values(by='rmse')['method'].tolist() # Сортируем для вывода\n",
    "print(pivot_table_select[current_rmse_order_select].round(4))\n",
    "\n",
    "\n",
    "# --- График прогноза (исправленный) ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Отображение части обучающей выборки\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date]\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "# Отображение реальных тестовых данных\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2)\n",
    "\n",
    "# Отображение прогноза Бленда\n",
    "forecast_blend_series = pd.Series(forecast_blend_select_eval, index=test.index[:len(forecast_blend_select_eval)])\n",
    "plt.plot(forecast_blend_series.index, forecast_blend_series, label=f'Прогноз {model_name_blend_select}', color='indigo', linestyle='--')\n",
    "\n",
    "# Отображение прогноза ARIMA для сравнения\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "\n",
    "# Настройки графика\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_blend_select}')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. График RMSE vs Горизонт (только для этой модели - Blend_ARIMA_Trees)\n",
    "# Убедимся, что DataFrame df_horizon_rmse_blend_select существует и не пуст\n",
    "try:\n",
    "    if not df_horizon_rmse_blend_select.empty:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(df_horizon_rmse_blend_select['horizon'], df_horizon_rmse_blend_select['rmse'], marker='o', linestyle='-', color='indigo') # Цвет бленда\n",
    "        plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_blend_select}')\n",
    "        plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "        plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "    else:\n",
    "        print(f\"Нет данных для построения графика RMSE vs Горизонт для {model_name_blend_select}\")\n",
    "except NameError:\n",
    "    print(f\"DataFrame df_horizon_rmse_blend_select не найден для графика RMSE vs Горизонт.\")\n",
    "\n",
    "\n",
    "print(f\"--- Анализ {model_name_blend_select} завершен ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFWJr_azw1n"
   },
   "source": [
    "# Гибрид Arima + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 40454,
     "status": "ok",
     "timestamp": 1746805019857,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "d_nggacuz1Xn",
    "outputId": "81818a52-e18b-4a22-ccaa-10ca9cb6a5ba"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 12: Гибридная Модель ARIMA+XGBoost_на_ошибках (hyperopt для XGB_err) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA as StatsmodelsARIMA\n",
    "# Убираем GridSearchCV, добавляем hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Убедимся, что tscv определен\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# X_train, y_train - НЕмасштабированные DataFrame и Series\n",
    "# X_test, y_test - для теста\n",
    "# tscv - настроенный TimeSeriesSplit\n",
    "# calculate_features_for_step, feature_order, test_months, horizons_to_evaluate\n",
    "# result_rmse, df_horizon_rmse, recursive_forecasts\n",
    "# plot_start_date, forecast_arima - рекурсивный прогноз ARIMA(1,0,0)\n",
    "# train_values, test_values - для графиков\n",
    "# random_seed\n",
    "# recursive_predict\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "# --- Дополнительные настройки ---\n",
    "model_name_hybrid = \"ARIMA+XGB_err_Rec_Tuned\" # <<<--- СОХРАНЯЕМ ИМЯ\n",
    "arima_order = (1, 0, 0)\n",
    "MAX_EVALS_HYPEROPT_XGB_ERR = 50 # Количество итераций для hyperopt XGBoost на ошибках\n",
    "# --- Конец Дополнительных настроек ---\n",
    "\n",
    "print(f\"\\n--- Обучение и Прогнозирование: {model_name_hybrid} ---\")\n",
    "\n",
    "# 1. Подготовка данных для моделирования ошибок ARIMA\n",
    "print(\"Подготовка данных для моделирования ошибок ARIMA...\")\n",
    "try:\n",
    "    # Пересчитываем ошибки ARIMA\n",
    "    arima_model_full_train = StatsmodelsARIMA(y_train, order=arima_order).fit()\n",
    "    arima_fitted_values_train = arima_model_full_train.fittedvalues.reindex(y_train.index)\n",
    "    first_valid_index_arima_fit = arima_fitted_values_train.first_valid_index()\n",
    "    if first_valid_index_arima_fit is None:\n",
    "        raise ValueError(\"ARIMA fitted values не содержат валидных данных.\")\n",
    "    start_pos_arima_fit = y_train.index.get_loc(first_valid_index_arima_fit)\n",
    "\n",
    "    y_train_aligned_for_errors = y_train.iloc[start_pos_arima_fit:]\n",
    "    arima_fitted_aligned_for_errors = arima_fitted_values_train.iloc[start_pos_arima_fit:]\n",
    "    X_train_aligned_for_errors = X_train.reindex(y_train_aligned_for_errors.index)\n",
    "\n",
    "    if X_train_aligned_for_errors.isnull().values.any():\n",
    "        print(\"Предупреждение: NaN в X_train_aligned_for_errors. Удаление строк с NaN...\")\n",
    "        nan_rows_index = X_train_aligned_for_errors[X_train_aligned_for_errors.isnull().any(axis=1)].index\n",
    "        X_train_aligned_for_errors = X_train_aligned_for_errors.dropna()\n",
    "        y_train_aligned_for_errors = y_train_aligned_for_errors.drop(nan_rows_index)\n",
    "        arima_fitted_aligned_for_errors = arima_fitted_aligned_for_errors.drop(nan_rows_index)\n",
    "        print(\"Строки с NaN удалены.\")\n",
    "\n",
    "    arima_errors_train_target = y_train_aligned_for_errors - arima_fitted_aligned_for_errors\n",
    "\n",
    "    print(f\"Размер X_train_aligned_for_errors: {X_train_aligned_for_errors.shape}\")\n",
    "    print(f\"Размер arima_errors_train_target: {arima_errors_train_target.shape}\")\n",
    "    if X_train_aligned_for_errors.empty or arima_errors_train_target.empty:\n",
    "         raise ValueError(\"Недостаточно данных после выравнивания и удаления NaN для обучения XGBoost на ошибках.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при подготовке данных для ошибок ARIMA: {e}\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "# 2. Определяем пространство поиска для hyperopt XGBoost на ошибках\n",
    "space_xgb_errors = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 25),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 4, 1), # Проверяем неглубокие деревья\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 1.0), # Чуть шире диапазон для gamma\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', np.log(0.001), np.log(1.0)),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', np.log(0.1), np.log(10.0))\n",
    "}\n",
    "print(f\"Пространство поиска для XGBoost на ошибках: {space_xgb_errors}\")\n",
    "\n",
    "# 3. Определяем целевую функцию (objective) для hyperopt XGBoost на ошибках\n",
    "def objective_xgb_errors(params):\n",
    "    \"\"\"\n",
    "    Целевая функция для hyperopt. Обучает XGBoost на ОШИБКАХ ARIMA\n",
    "    и оценивает его с помощью TimeSeriesSplit кросс-валидации.\n",
    "    Возвращает средний RMSE по фолдам предсказания ошибок.\n",
    "    \"\"\"\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    rmses = []\n",
    "    try:\n",
    "        # ВАЖНО: CV проводим на выровненных данных и ошибках\n",
    "        for train_idx, val_idx in tscv.split(X_train_aligned_for_errors):\n",
    "            # Используем .iloc, так как это Pandas объекты\n",
    "            X_fold_train_err, X_fold_val_err = X_train_aligned_for_errors.iloc[train_idx], X_train_aligned_for_errors.iloc[val_idx]\n",
    "            y_fold_train_err, y_fold_val_err = arima_errors_train_target.iloc[train_idx], arima_errors_train_target.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_fold_train_err, y_fold_train_err)\n",
    "            preds_err = model.predict(X_fold_val_err)\n",
    "\n",
    "            if not np.all(np.isfinite(preds_err)) or not np.all(np.isfinite(y_fold_val_err.values)):\n",
    "                 continue\n",
    "            if len(y_fold_val_err) == 0:\n",
    "                 continue\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val_err, preds_err))\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        if not rmses: avg_rmse = 1e10\n",
    "        else: avg_rmse = np.mean(rmses)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error during CV for errors, params={params}: {e}\") # Отладка\n",
    "        avg_rmse = 1e10\n",
    "\n",
    "    if not np.isfinite(avg_rmse): avg_rmse = 1e10\n",
    "\n",
    "    return {'loss': avg_rmse, 'status': STATUS_OK }\n",
    "\n",
    "# 4. Запускаем оптимизацию hyperopt для XGBoost на ошибках\n",
    "print(f\"Запуск hyperopt для подбора параметров XGBoost на ошибках (max_evals={MAX_EVALS_HYPEROPT_XGB_ERR})...\")\n",
    "trials_xgb_errors = Trials()\n",
    "\n",
    "try:\n",
    "    rstate_xgb_err = np.random.default_rng(random_seed)\n",
    "except AttributeError:\n",
    "    rstate_xgb_err = np.random.RandomState(random_seed)\n",
    "\n",
    "best_params_raw_xgb_err = fmin(\n",
    "    fn=objective_xgb_errors,\n",
    "    space=space_xgb_errors,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=MAX_EVALS_HYPEROPT_XGB_ERR,\n",
    "    trials=trials_xgb_errors,\n",
    "    rstate=rstate_xgb_err,\n",
    "    show_progressbar=True\n",
    ")\n",
    "\n",
    "# Преобразуем и получаем лучшие параметры\n",
    "best_final_params_xgb_err = space_eval(space_xgb_errors, best_params_raw_xgb_err)\n",
    "best_final_params_xgb_err['n_estimators'] = int(best_final_params_xgb_err['n_estimators'])\n",
    "best_final_params_xgb_err['max_depth'] = int(best_final_params_xgb_err['max_depth'])\n",
    "\n",
    "try:\n",
    "    best_cv_rmse_xgb_err = trials_xgb_errors.best_trial['result']['loss']\n",
    "    print(f\"\\nЛучшие найденные параметры для XGBoost на ошибках: {best_final_params_xgb_err}\")\n",
    "    print(f\"Лучший RMSE на CV для ошибок ARIMA: {best_cv_rmse_xgb_err:.4f}\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nНе удалось извлечь лучший результат из hyperopt trials для ошибок: {e}\")\n",
    "     raise SystemExit(\"Прерывание из-за ошибки в hyperopt для ошибок.\")\n",
    "\n",
    "# 5. Обучаем финальную модель XGBoost на ВСЕХ ошибках ARIMA с лучшими параметрами\n",
    "print(\"\\nОбучение финальной модели XGBoost на всех ошибках ARIMA...\")\n",
    "final_xgb_error_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1,\n",
    "    **best_final_params_xgb_err # Используем параметры, найденные для ошибок\n",
    ")\n",
    "final_xgb_error_model.fit(X_train_aligned_for_errors, arima_errors_train_target)\n",
    "print(\"Финальная модель XGBoost на ошибках обучена.\")\n",
    "\n",
    "\n",
    "# 6. Получаем рекурсивный прогноз ARIMA (он уже должен быть в forecast_arima)\n",
    "test_arima_preds_rec = forecast_arima[:test_months]\n",
    "\n",
    "# 7. Делаем РЕКУРСИВНЫЙ прогноз ошибок XGBoost с использованием ОТТЮНИНГОВАННОЙ модели\n",
    "print(\"\\nГенерация рекурсивного прогноза ошибок XGBoost (с оттюнингованной моделью)...\")\n",
    "initial_history_hybrid = y_train.copy() # Используем историю y для расчета признаков!\n",
    "test_error_preds_xgb_recursive = recursive_predict(\n",
    "    model=final_xgb_error_model, # <<<--- Используем финальную модель XGBoost на ошибках\n",
    "    initial_history_series=initial_history_hybrid,\n",
    "    n_steps=test_months,\n",
    "    feature_calculator=calculate_features_for_step,\n",
    "    feature_order=feature_order,\n",
    "    scaler=None # XGBoost обучался на немасштабированных признаках\n",
    ")\n",
    "print(\"Рекурсивный прогноз ошибок сгенерирован.\")\n",
    "\n",
    "# 8. Комбинируем рекурсивные прогнозы\n",
    "print(\"\\nКомбинирование прогнозов ARIMA и XGBoost_error...\")\n",
    "final_forecast_hybrid_recursive = test_arima_preds_rec + test_error_preds_xgb_recursive\n",
    "# Обновляем словарь прогнозов, СОХРАНЯЯ ИМЯ МОДЕЛИ\n",
    "if model_name_hybrid in recursive_forecasts: del recursive_forecasts[model_name_hybrid]\n",
    "recursive_forecasts[model_name_hybrid] = final_forecast_hybrid_recursive[:test_months]\n",
    "print(f\"Прогноз {model_name_hybrid} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "# 6. Оценка RMSE\n",
    "# Проверка длин (на всякий случай, если recursive_predict вернет меньше шагов)\n",
    "if len(final_forecast_hybrid_recursive) != len(y_test):\n",
    "     min_len = min(len(final_forecast_hybrid_recursive), len(y_test))\n",
    "     print(f\"Предупреждение: Длина гибридного прогноза ({len(final_forecast_hybrid_recursive)}) не совпадает с y_test ({len(y_test)}). Используется длина {min_len}.\")\n",
    "     y_test_eval = y_test[:min_len]\n",
    "     forecast_hybrid_eval = final_forecast_hybrid_recursive[:min_len]\n",
    "else:\n",
    "     y_test_eval = y_test\n",
    "     forecast_hybrid_eval = final_forecast_hybrid_recursive\n",
    "\n",
    "overall_rmse_hybrid_recursive = np.sqrt(mean_squared_error(y_test_eval, forecast_hybrid_eval))\n",
    "print(f\"\\nОбщий RMSE на тесте для {model_name_hybrid}: {overall_rmse_hybrid_recursive:.4f}\")\n",
    "\n",
    "# Добавляем/Обновляем общий RMSE\n",
    "# Удаляем старые гибриды или гибриды с похожими именами\n",
    "result_rmse = result_rmse[~result_rmse['method'].str.contains('ARIMA\\+XGB_err', case=False)]\n",
    "result_hybrid_entry = {'method': model_name_hybrid, 'rmse': overall_rmse_hybrid_recursive}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_hybrid_entry])], ignore_index=True)\n",
    "\n",
    "# Расчет и добавление RMSE по горизонтам\n",
    "print(\"RMSE по горизонтам:\")\n",
    "df_horizon_rmse = df_horizon_rmse[~df_horizon_rmse['method'].str.contains('ARIMA\\+XGB_err', case=False)]\n",
    "horizon_results_list_hybrid_rec = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(forecast_hybrid_eval): # Используем длину фактического прогноза\n",
    "        forecast_h_step = forecast_hybrid_eval[:h]\n",
    "        actual_h_step = y_test_eval[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h_step, forecast_h_step))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\")\n",
    "        horizon_results_list_hybrid_rec.append({'method': model_name_hybrid, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse_hybrid_rec = pd.DataFrame(horizon_results_list_hybrid_rec)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_hybrid_rec], ignore_index=True)\n",
    "print(\"Результаты RMSE по горизонтам добавлены/обновлены.\")\n",
    "\n",
    "# 7. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot_hybrid = train_values[train_values.index >= plot_start_date] # Используем train_values\n",
    "plt.plot(history_to_plot_hybrid.index, history_to_plot_hybrid, label='Обучающая выборка (часть)')\n",
    "plt.plot(y_test_eval.index, y_test_eval, label='Тестовая выборка (реальные)', color='orange', linewidth=2) # Используем y_test_eval\n",
    "forecast_hybrid_series = pd.Series(forecast_hybrid_eval, index=y_test_eval.index[:len(forecast_hybrid_eval)])\n",
    "plt.plot(forecast_hybrid_series.index, forecast_hybrid_series, label=f'Прогноз {model_name_hybrid}', color='brown', linestyle='--')\n",
    "# Прогноз ARIMA для сравнения\n",
    "forecast_arima_series_plot = pd.Series(test_arima_preds_rec, index=y_test_eval.index[:len(test_arima_preds_rec)])\n",
    "plt.plot(forecast_arima_series_plot.index, forecast_arima_series_plot, label='Прогноз ARIMA (база)', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_hybrid}')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 8. График RMSE vs Горизонт (только для этой модели)\n",
    "if not df_horizon_rmse_hybrid_rec.empty:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_horizon_rmse_hybrid_rec['horizon'], df_horizon_rmse_hybrid_rec['rmse'], marker='o', linestyle='-')\n",
    "    plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_hybrid}')\n",
    "    plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "    plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "else:\n",
    "    print(f\"Нет данных для построения графика RMSE vs Горизонт для {model_name_hybrid}\")\n",
    "\n",
    "\n",
    "print(f\"--- Анализ {model_name_hybrid} завершен ---\")\n",
    "\n",
    "# 9. Вывод итоговых таблиц\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_current_hybrid = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "current_order_hybrid = result_rmse.sort_values(by='rmse')['method'].tolist()\n",
    "\n",
    "# Добавляем недостающие колонки, если они есть в current_order_hybrid, но нет в pivot_table_current_hybrid\n",
    "for method in current_order_hybrid:\n",
    "     if method not in pivot_table_current_hybrid.columns:\n",
    "         pivot_table_current_hybrid[method] = np.nan\n",
    "# Убедимся, что новая модель есть в current_order_hybrid, если result_rmse не успел обновиться корректно\n",
    "if model_name_hybrid not in current_order_hybrid:\n",
    "    current_order_hybrid.append(model_name_hybrid)\n",
    "# Попытаемся вывести в отсортированном порядке, но если колонки нет - выведем как есть\n",
    "try:\n",
    "    print(pivot_table_current_hybrid[current_order_hybrid].round(4))\n",
    "except KeyError as e:\n",
    "     print(f\"Ошибка при сортировке колонок для вывода RMSE по горизонтам: {e}. Вывод как есть:\")\n",
    "     print(pivot_table_current_hybrid.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1746805485537,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "Zun-uE1nt-c3",
    "outputId": "4816e4a0-4ae8-4168-cd02-8025802c8d7d"
   },
   "outputs": [],
   "source": [
    "# 7. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot_hybrid = train_values[train_values.index >= plot_start_date] # Используем train_values\n",
    "plt.plot(history_to_plot_hybrid.index, history_to_plot_hybrid, label='Обучающая выборка (часть)')\n",
    "plt.plot(y_test_eval.index, y_test_eval, label='Тестовая выборка (реальные)', color='orange', linewidth=2) # Используем y_test_eval\n",
    "forecast_hybrid_series = pd.Series(forecast_hybrid_eval, index=y_test_eval.index[:len(forecast_hybrid_eval)])\n",
    "plt.plot(forecast_hybrid_series.index, forecast_hybrid_series, label=f'Прогноз {model_name_hybrid}', color='brown', linestyle='--')\n",
    "forecast_blend_series = pd.Series(forecast_blend_select_eval, index=test.index[:len(forecast_blend_select_eval)])\n",
    "plt.plot(forecast_blend_series.index, forecast_blend_series, label=f'Прогноз {model_name_blend_select}', color='indigo', linestyle='--')\n",
    "# Прогноз ARIMA для сравнения\n",
    "forecast_arima_series_plot = pd.Series(test_arima_preds_rec, index=y_test_eval.index[:len(test_arima_preds_rec)])\n",
    "plt.plot(forecast_arima_series_plot.index, forecast_arima_series_plot, label='Прогноз ARIMA (база)', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_hybrid}')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0O06Iw91bMD"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15331,
     "status": "ok",
     "timestamp": 1746742994547,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "rcFxGP7p1cS8",
    "outputId": "a8d208d6-c07e-4334-f961-5e95b67f74dd"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 11: Модель LSTM (Обучение + Рекурсивный Прогноз) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# data_ml: DataFrame с колонкой 't' и DatetimeIndex\n",
    "# train_ml: DataFrame обучающей выборки (для определения длины)\n",
    "# test: DataFrame тестовой выборки (для индекса графика)\n",
    "# y_test: pd.Series с реальными значениями на тесте\n",
    "# test_months: Количество месяцев в тесте (24)\n",
    "# horizons_to_evaluate: Список горизонтов [1, 2, 3, 6, 12, 18, 24]\n",
    "# result_rmse, df_horizon_rmse: DataFrames для результатов\n",
    "# recursive_forecasts: Словарь для прогнозов\n",
    "# plot_start_date, history_points_to_show\n",
    "# forecast_nonseasonal (или forecast_arima): Прогноз ARIMA\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "# --- Настройки LSTM ---\n",
    "cpi_value_column_lstm = 't' # Используем колонку 't' из data_ml\n",
    "look_back_lstm = 12\n",
    "lstm_units = 50\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "validation_split = 0.1\n",
    "patience_early_stopping = 10\n",
    "model_name_lstm = \"LSTM\"\n",
    "random_seed = 42\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed) # Для numpy операций, если они есть в подготовке\n",
    "# --- Конец Настроек ---\n",
    "\n",
    "print(f\"\\n--- Обучение и Прогнозирование: {model_name_lstm} ---\")\n",
    "\n",
    "# 1. Подготовка данных (масштабирование и создание последовательностей)\n",
    "print(\"Подготовка данных для LSTM...\")\n",
    "lstm_input_series = data_ml[cpi_value_column_lstm].copy()\n",
    "scaler_lstm = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data_lstm = scaler_lstm.fit_transform(lstm_input_series.values.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(data, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:(i + look_back), 0])\n",
    "        Y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "X_seq_lstm, y_seq_lstm = create_sequences(scaled_data_lstm, look_back_lstm)\n",
    "\n",
    "# Разделение на train/test\n",
    "n_train_sequences_lstm = len(train_ml) - look_back_lstm\n",
    "X_train_lstm = X_seq_lstm[:n_train_sequences_lstm]\n",
    "y_train_lstm = y_seq_lstm[:n_train_sequences_lstm]\n",
    "# X_test_lstm_input нам не нужен для рекурсивного прогноза\n",
    "\n",
    "# Reshape X_train_lstm для обучения\n",
    "X_train_lstm = np.reshape(X_train_lstm, (X_train_lstm.shape[0], X_train_lstm.shape[1], 1))\n",
    "print(f\"Размер обучающей выборки LSTM (X, y): {X_train_lstm.shape}, {y_train_lstm.shape}\")\n",
    "\n",
    "# 2. Построение и компиляция модели\n",
    "print(\"\\nПостроение и компиляция модели LSTM...\")\n",
    "model_lstm = Sequential([\n",
    "    LSTM(units=lstm_units, input_shape=(look_back_lstm, 1)),\n",
    "    Dense(units=1)\n",
    "])\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# model_lstm.summary() # Можно раскомментировать\n",
    "\n",
    "# 3. Обучение модели\n",
    "print(\"\\nОбучение модели LSTM...\")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_early_stopping,\n",
    "                               verbose=0, mode='min', restore_best_weights=True) # verbose=0 тихий режим\n",
    "history = model_lstm.fit(X_train_lstm, y_train_lstm,\n",
    "                         epochs=epochs, batch_size=batch_size,\n",
    "                         validation_split=validation_split,\n",
    "                         callbacks=[early_stopping], verbose=0)\n",
    "print(f\"Обучение завершено. Остановлено на эпохе: {early_stopping.stopped_epoch+1}\") # +1 т.к. нумерация с 0\n",
    "print(f\"Лучшая val_loss: {early_stopping.best:.4f}\")\n",
    "\n",
    "# 4. Генерация рекурсивного прогноза\n",
    "print(\"\\nГенерация рекурсивного прогноза...\")\n",
    "last_train_sequence_scaled = X_train_lstm[-1] # Берем последнюю ПОСЛЕДОВАТЕЛЬНОСТЬ из X_train_lstm\n",
    "predictions_scaled_lstm = []\n",
    "current_sequence_lstm = last_train_sequence_scaled.reshape(1, look_back_lstm, 1)\n",
    "\n",
    "for i in range(test_months):\n",
    "    next_pred_scaled = model_lstm.predict(current_sequence_lstm, verbose=0)[0, 0]\n",
    "    predictions_scaled_lstm.append(next_pred_scaled)\n",
    "    next_sequence_values = np.append(current_sequence_lstm[0, 1:, 0], next_pred_scaled)\n",
    "    current_sequence_lstm = next_sequence_values.reshape(1, look_back_lstm, 1)\n",
    "\n",
    "predictions_scaled_lstm = np.array(predictions_scaled_lstm)\n",
    "forecast_lstm = scaler_lstm.inverse_transform(predictions_scaled_lstm.reshape(-1, 1)).flatten()\n",
    "# Добавляем прогноз в общий словарь\n",
    "recursive_forecasts[model_name_lstm] = forecast_lstm[:test_months]\n",
    "print(f\"Прогноз {model_name_lstm} сгенерирован и добавлен в словарь.\")\n",
    "\n",
    "# 5. Оценка RMSE\n",
    "# Проверка длин\n",
    "if len(forecast_lstm) != len(y_test):\n",
    "     min_len = min(len(forecast_lstm), len(y_test));\n",
    "     y_test_eval = y_test[:min_len]; forecast_lstm_eval = forecast_lstm[:min_len]\n",
    "else:\n",
    "     y_test_eval = y_test; forecast_lstm_eval = forecast_lstm\n",
    "\n",
    "overall_rmse_lstm = np.sqrt(mean_squared_error(y_test_eval, forecast_lstm_eval))\n",
    "print(f\"\\nОбщий RMSE на тесте для {model_name_lstm}: {overall_rmse_lstm:.4f}\")\n",
    "\n",
    "# Добавляем/Обновляем общий RMSE\n",
    "result_rmse = result_rmse[~result_rmse['method'].isin([model_name_lstm])]\n",
    "result_lstm_entry = {'method': model_name_lstm, 'rmse': overall_rmse_lstm}\n",
    "result_rmse = pd.concat([result_rmse, pd.DataFrame([result_lstm_entry])], ignore_index=True)\n",
    "\n",
    "# Расчет и добавление RMSE по горизонтам\n",
    "print(\"RMSE по горизонтам:\")\n",
    "df_horizon_rmse = df_horizon_rmse[~df_horizon_rmse['method'].isin([model_name_lstm])]\n",
    "horizon_results_list_lstm = []\n",
    "for h in horizons_to_evaluate:\n",
    "    if h <= len(y_test_eval):\n",
    "        forecast_h = forecast_lstm_eval[:h]\n",
    "        actual_h = y_test_eval[:h]\n",
    "        rmse_h = np.sqrt(mean_squared_error(actual_h, forecast_h))\n",
    "        print(f\"  1-{h} мес.: {rmse_h:.4f}\") # Вывод промежуточного RMSE\n",
    "        horizon_results_list_lstm.append({'method': model_name_lstm, 'horizon': h, 'rmse': rmse_h})\n",
    "df_horizon_rmse_lstm = pd.DataFrame(horizon_results_list_lstm)\n",
    "df_horizon_rmse = pd.concat([df_horizon_rmse, df_horizon_rmse_lstm], ignore_index=True)\n",
    "print(\"Результаты RMSE по горизонтам добавлены/обновлены.\")\n",
    "\n",
    "# 6. График прогноза\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_to_plot = train_values[train_values.index >= plot_start_date] # Используем train_values\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обучающая выборка (часть)')\n",
    "plt.plot(test.index, test_values, label='Тестовая выборка (реальные)', color='orange', linewidth=2) # Используем test_values\n",
    "forecast_lstm_series = pd.Series(forecast_lstm_eval, index=test.index[:len(forecast_lstm_eval)])\n",
    "plt.plot(forecast_lstm_series.index, forecast_lstm_series, label=f'Прогноз {model_name_lstm}', color='lime', linestyle='--')\n",
    "# Добавляем ARIMA для сравнения (используем forecast_arima)\n",
    "forecast_arima_series = pd.Series(forecast_arima, index=test.index[:len(forecast_arima)])\n",
    "plt.plot(forecast_arima_series.index, forecast_arima_series, label='Прогноз ARIMA', color='blue', linestyle=':', alpha=0.7)\n",
    "plt.title(f'Прогноз ИПЦ с помощью {model_name_lstm}')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)'); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7. График RMSE vs Горизонт (только для этой модели)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_horizon_rmse_lstm['horizon'], df_horizon_rmse_lstm['rmse'], marker='o', linestyle='-')\n",
    "plt.title(f'Зависимость RMSE от горизонта прогноза для {model_name_lstm}')\n",
    "plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "plt.xticks(horizons_to_evaluate); plt.grid(True); plt.show()\n",
    "\n",
    "print(f\"--- Анализ {model_name_lstm} завершен ---\")\n",
    "\n",
    "# 8. Вывод итоговых таблиц\n",
    "print(\"\\nТекущая таблица общих RMSE:\")\n",
    "print(result_rmse.sort_values(by='rmse'))\n",
    "print(\"\\nТекущая таблица RMSE по горизонтам:\")\n",
    "pivot_table_current = df_horizon_rmse.pivot(index='horizon', columns='method', values='rmse')\n",
    "current_order = result_rmse.sort_values(by='rmse')['method'].tolist()\n",
    "for method in current_order:\n",
    "     if method not in pivot_table_current.columns: pivot_table_current[method] = np.nan\n",
    "if model_name_lstm not in current_order: current_order.append(model_name_lstm)\n",
    "try:\n",
    "    print(pivot_table_current[current_order].round(4))\n",
    "except KeyError as e:\n",
    "     print(f\"Ошибка при сортировке колонок: {e}. Вывод как есть:\")\n",
    "     print(pivot_table_current.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1746743042131,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "lQtHzvdM5GMj",
    "outputId": "29335c44-3e78-4908-e6cd-c4370b884e21"
   },
   "outputs": [],
   "source": [
    "print(pivot_table_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Nr3lp82aRG"
   },
   "source": [
    "# Графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1630,
     "status": "ok",
     "timestamp": 1746807653996,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "4bDVLqv_2ZXu",
    "outputId": "ea92d31e-18dd-4fe7-9689-59f2b2466671"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 13: Финальные Сравнительные Графики (Рекурсивные прогнозы) ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ---\n",
    "# df_horizon_rmse: Актуальный DataFrame с RMSE по горизонтам для всех рекурсивных моделей\n",
    "# result_rmse: Актуальный DataFrame с общими RMSE\n",
    "# recursive_forecasts: Актуальный словарь со всеми прогнозами\n",
    "# y_train, y_test: Series с обучающими и тестовыми данными\n",
    "# train_values, test_values: То же самое\n",
    "# test_ml.index: Индекс тестового периода\n",
    "# plot_start_date, history_points_to_show, horizons_to_evaluate\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "print(\"\\n--- Построение Финальных Сравнительных Графиков ---\")\n",
    "\n",
    "# 1. График RMSE vs Горизонт\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Определяем порядок моделей по финальному общему RMSE\n",
    "final_model_order = result_rmse.sort_values(by='rmse')['method'].tolist()\n",
    "\n",
    "# Задаем палитру\n",
    "custom_palette = {\n",
    "    \"ARIMA\": \"blue\", \"Mean\": \"grey\", \"LSTM\": \"lime\", \"Median\": \"black\",\n",
    "    \"Blend_ARIMA_Trees\": \"indigo\", \"XGB_Recursive\": \"red\", \"ARIMA+XGB_err_Rec_Tuned\":\"darkred\",\n",
    "    \"RF_Recursive\": \"teal\", \"Lasso_Recursive\": \"purple\", \"Ridge_Recursive\": \"orange\",\n",
    "    \"Trend\": \"pink\",\n",
    "    \"Blend_ML_Recursive\": \"fuchsia\", \"Blend_Trees_Recursive\": \"cyan\",\n",
    "    \"ARIMA+XGB_err_Rec\": \"brown\"\n",
    "}\n",
    "\n",
    "# Строим график\n",
    "sns.lineplot(data=df_horizon_rmse, x='horizon', y='rmse', hue='method',\n",
    "             hue_order=final_model_order, palette=custom_palette, marker='o', linewidth=1.5)\n",
    "\n",
    "plt.title('Сравнение RMSE моделей на разных горизонтах прогноза (Рекурсивные)')\n",
    "plt.xlabel('Горизонт прогноза (месяцы)'); plt.ylabel('RMSE')\n",
    "plt.xticks(horizons_to_evaluate); plt.grid(True)\n",
    "plt.legend(title='Модель', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1]); plt.show()\n",
    "\n",
    "\n",
    "# 2. График Реальность vs Прогнозы\n",
    "plt.figure(figsize=(15, 8))\n",
    "# История\n",
    "history_to_plot = train_values[train_values.index >= '2022-09-01']\n",
    "plt.plot(history_to_plot.index, history_to_plot, label='Обуч. (часть)')\n",
    "# Реальность\n",
    "plt.plot(test.index, test_values, label='Реальные (тест)', color='orange', linewidth=2.5, marker='o', markersize=4, zorder=10)\n",
    "\n",
    "# Выбираем КЛЮЧЕВЫЕ модели для отображения (лидеры и лучшие ML/ансамбли)\n",
    "# models_to_plot_final = ['ARIMA', 'LSTM', 'Mean', 'Median', 'Blend_ARIMA_Trees', 'XGB_Recursive', 'ARIMA+XGB_err_Rec', 'RF_Recursive', 'Trend']\n",
    "\n",
    "for model_name in final_model_order:\n",
    "    if model_name in recursive_forecasts:\n",
    "        forecast = recursive_forecasts[model_name]\n",
    "        plot_len = min(len(forecast), len(test.index)) # Используем test.index\n",
    "        # Создаем Series для корректной отрисовки с DatetimeIndex\n",
    "        forecast_series = pd.Series(forecast[:plot_len], index=test.index[:plot_len])\n",
    "        plt.plot(forecast_series.index, forecast_series,\n",
    "                 label=f'Прогноз {model_name}',\n",
    "                 color=custom_palette.get(model_name, None),\n",
    "                 linestyle='--', linewidth=1.5, alpha=0.9)\n",
    "    else:\n",
    "        print(f\"Предупреждение: Прогноз для {model_name} не найден в словаре recursive_forecasts для графика.\")\n",
    "\n",
    "plt.title('Сравнение прогнозов ключевых моделей с реальными данными (Рекурсивные)')\n",
    "plt.xlabel('Дата'); plt.ylabel('ИПЦ (месячный рост)')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "plt.grid(True); plt.tight_layout(rect=[0, 0, 0.85, 1]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvD8g_uM4FLk"
   },
   "source": [
    "# DM-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1746807657518,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "5Dy_bUPb4HKe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "import collections\n",
    "\n",
    "def dm_test(actual_lst, pred1_lst, pred2_lst, h = 1, crit=\"MSE\", power = 2):\n",
    "    # Проверка длин\n",
    "    if not (len(actual_lst) == len(pred1_lst) == len(pred2_lst)):\n",
    "         raise ValueError(\"Lengths of actual_lst, pred1_lst and pred2_lst must be equal.\")\n",
    "    if len(actual_lst) < 2:\n",
    "         return collections.namedtuple('dm_return' , 'DM p_value')(DM = np.nan, p_value = np.nan)\n",
    "    if h < 1:\n",
    "         raise ValueError(\"Horizon h must be 1 or greater.\")\n",
    "\n",
    "    # Initialise lists\n",
    "    e1_lst = []\n",
    "    e2_lst = []\n",
    "    d_lst  = []\n",
    "\n",
    "    # Calculate loss differential\n",
    "    if crit == \"MSE\":\n",
    "        for actual,p1,p2 in zip(actual_lst, pred1_lst, pred2_lst):\n",
    "            e1_lst.append((actual - p1)**2)\n",
    "            e2_lst.append((actual - p2)**2)\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    elif crit == \"MAD\":\n",
    "        for actual,p1,p2 in zip(actual_lst, pred1_lst, pred2_lst):\n",
    "            e1_lst.append(abs(actual - p1))\n",
    "            e2_lst.append(abs(actual - p2))\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    else:\n",
    "         raise ValueError(f\"Criterion {crit} not supported. Use 'MSE' or 'MAD'.\")\n",
    "\n",
    "    # Mean of d\n",
    "    mean_d = pd.Series(d_lst).mean()\n",
    "    if np.isnan(mean_d):\n",
    "        return collections.namedtuple('dm_return' , 'DM p_value')(DM = np.nan, p_value = np.nan)\n",
    "\n",
    "    # Newey-West variance estimator\n",
    "    T = float(len(d_lst))\n",
    "    max_lag = min(h - 1, T - 1)\n",
    "\n",
    "    gamma = []\n",
    "    for lag in range(int(max_lag + 1)):\n",
    "        autoCov = 0\n",
    "        for i in range(lag, len(d_lst)):\n",
    "              autoCov += (d_lst[i] - mean_d) * (d_lst[i-lag] - mean_d)\n",
    "        gamma.append(autoCov / T)\n",
    "\n",
    "    V_d = gamma[0]\n",
    "    if max_lag > 0:\n",
    "        for k in range(1, int(max_lag + 1)):\n",
    "            weight = 1 - (k / (max_lag + 1))\n",
    "            V_d += 2 * weight * gamma[k]\n",
    "\n",
    "    # DM statistic\n",
    "    if V_d <= 1e-9:\n",
    "        return collections.namedtuple('dm_return' , 'DM p_value')(DM = np.nan, p_value = 1.0)\n",
    "\n",
    "    DM_stat = mean_d / np.sqrt(V_d / T)\n",
    "    df = T - 1\n",
    "    if df <= 0:\n",
    "        return collections.namedtuple('dm_return' , 'DM p_value')(DM = np.nan, p_value = np.nan)\n",
    "\n",
    "    p_value = 2 * t.cdf(-abs(DM_stat), df = df)\n",
    "    rt = collections.namedtuple('dm_return' , 'DM p_value')(DM = DM_stat, p_value = p_value)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5259,
     "status": "ok",
     "timestamp": 1746743116832,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "ay_ILDqn5C_V",
    "outputId": "a4372fdf-8e7c-4aeb-aab5-431e10d012b6"
   },
   "outputs": [],
   "source": [
    "# --- БЛОК 5: Финальный Тест Диболда-Мариано (Метод Холма) ---\n",
    "\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from itertools import combinations\n",
    "import pandas as pd # Убедимся, что pandas импортирован\n",
    "import numpy as np # И numpy\n",
    "\n",
    "# --- ПРЕДПОЛАГАЕМ, ЧТО ПЕРЕМЕННЫЕ СУЩЕСТВУЮТ ИЗ ПРЕДЫДУЩИХ БЛОКОВ ---\n",
    "# recursive_forecasts: Словарь со всеми прогнозами, включая ключевые модели.\n",
    "# df_horizon_rmse: DataFrame с RMSE по горизонтам для всех моделей.\n",
    "# y_test: Series с реальными значениями на тесте.\n",
    "# horizons_to_evaluate: Список горизонтов [1, 2, 3, 6, 12, 18, 24].\n",
    "# dm_test: Функция теста Диболда-Мариано (должна быть определена ранее).\n",
    "# --- КОНЕЦ ПРЕДПОЛОЖЕНИЙ ---\n",
    "\n",
    "\n",
    "print(\"\\n--- Финальный Тест Диболда-Мариано (Метод Холма) ---\")\n",
    "alpha_family = 0.05\n",
    "# Выбираем ключевых игроков для сравнения\n",
    "models_to_compare_dm = ['ARIMA', 'LSTM', 'Mean', 'Blend_ARIMA_Trees', 'XGB_Recursive', 'ARIMA+XGB_err_Rec_Tuned', 'RF_Recursive'] # Выбрали лучших и базовые\n",
    "# models_to_compare_dm = final_model_order\n",
    "# Убедимся, что все модели из списка есть в наших результатах\n",
    "existing_models_for_dm = [m for m in models_to_compare_dm if m in result_rmse['method'].values]\n",
    "if len(existing_models_for_dm) < len(models_to_compare_dm):\n",
    "    print(\"Предупреждение: Не все модели из списка models_to_compare_dm найдены в результатах.\")\n",
    "    print(\"Сравнение будет проведено для:\", existing_models_for_dm)\n",
    "models_to_compare_dm = existing_models_for_dm # Используем только существующие\n",
    "\n",
    "# Пересчитываем поправку для этого набора сравнений\n",
    "num_models_dm = len(models_to_compare_dm)\n",
    "num_pairs_dm = num_models_dm * (num_models_dm - 1) // 2\n",
    "valid_horizons_for_dm = [h for h in horizons_to_evaluate if h >= 2 and h <= len(y_test)]\n",
    "num_valid_horizons_for_dm = len(valid_horizons_for_dm)\n",
    "total_tests_dm = num_pairs_dm * num_valid_horizons_for_dm\n",
    "# alpha_individual_holm = alpha_family # Для метода Холма НЕ нужен отдельный порог, используем общий alpha\n",
    "\n",
    "print(f\"Сравнение {num_models_dm} моделей на {num_valid_horizons_for_dm} горизонтах ({num_pairs_dm} пар на горизонт, {total_tests_dm} тестов)\")\n",
    "print(f\"Контроль FWER на уровне {alpha_family:.2f} для каждого горизонта методом Холма.\")\n",
    "\n",
    "dm_results_final = {} # Словарь для p-values этого набора тестов\n",
    "\n",
    "for h in valid_horizons_for_dm:\n",
    "    print(f\"\\n--- Горизонт: 1-{h} мес. ---\")\n",
    "    actual_h = y_test[:h]\n",
    "    p_values_h = []\n",
    "    pairs_h = []\n",
    "\n",
    "    # Используем combinations из itertools\n",
    "    for model1, model2 in combinations(models_to_compare_dm, 2):\n",
    "        # Проверяем наличие прогнозов в основном словаре\n",
    "        if model1 not in recursive_forecasts or model2 not in recursive_forecasts:\n",
    "             print(f\"    Предупреждение: Пропуск пары {model1} vs {model2} - прогноз отсутствует.\")\n",
    "             continue\n",
    "        forecast1_h = recursive_forecasts[model1][:h]\n",
    "        forecast2_h = recursive_forecasts[model2][:h]\n",
    "\n",
    "        # Проверка совпадения длин перед тестом\n",
    "        if len(actual_h) != len(forecast1_h) or len(actual_h) != len(forecast2_h):\n",
    "            print(f\"    Предупреждение: Несовпадение длин для {model1} vs {model2} на горизонте {h}. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            dm_res = dm_test(actual_h, forecast1_h, forecast2_h, h=h, crit=\"MSE\")\n",
    "            p_val = dm_res.p_value\n",
    "            if not pd.isna(p_val):\n",
    "                 p_values_h.append(p_val)\n",
    "                 pairs_h.append(tuple(sorted((model1, model2)))) # Сохраняем пару\n",
    "        except Exception as e:\n",
    "            print(f\"    Ошибка DM теста для {model1} vs {model2} на горизонте {h}: {e}\")\n",
    "\n",
    "    if not p_values_h:\n",
    "        print(\"\\nПары со значимыми различиями (Метод Холма):\")\n",
    "        print(\"  Нет (нет валидных p-values).\")\n",
    "        continue\n",
    "\n",
    "    # Применяем метод Холма\n",
    "    try:\n",
    "        reject_holm, pvals_corrected_holm, _, _ = multipletests(p_values_h,\n",
    "                                                                 alpha=alpha_family,\n",
    "                                                                 method='holm')\n",
    "    except Exception as e:\n",
    "        print(f\"    Ошибка при применении multipletests (Holm): {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    print(\"\\nПары со значимыми различиями (Метод Холма):\")\n",
    "    significant_pairs_holm = []\n",
    "    for i, reject in enumerate(reject_holm):\n",
    "        if reject:\n",
    "            model1, model2 = pairs_h[i] # Получаем пару по индексу\n",
    "            p_val_original = p_values_h[i]\n",
    "            p_val_corrected = pvals_corrected_holm[i]\n",
    "            try:\n",
    "                # Получаем RMSE из df_horizon_rmse\n",
    "                rmse1 = df_horizon_rmse.loc[(df_horizon_rmse['method'] == model1) & (df_horizon_rmse['horizon'] == h), 'rmse'].iloc[0]\n",
    "                rmse2 = df_horizon_rmse.loc[(df_horizon_rmse['method'] == model2) & (df_horizon_rmse['horizon'] == h), 'rmse'].iloc[0]\n",
    "                better_model = model1 if rmse1 < rmse2 else model2\n",
    "                worse_model = model2 if rmse1 < rmse2 else model1\n",
    "                significant_pairs_holm.append(f\"  {better_model} лучше {worse_model} (p_orig={p_val_original:.4f}, p_holm={p_val_corrected:.4f})\")\n",
    "            except IndexError:\n",
    "                 significant_pairs_holm.append(f\"  {model1} vs {model2} (p_orig={p_val_original:.4f}, p_holm={p_val_corrected:.4f}) - не удалось сравнить RMSE\")\n",
    "            except Exception as e_inner:\n",
    "                 print(f\"    Внутренняя ошибка при сравнении RMSE для {model1} vs {model2}: {e_inner}\")\n",
    "                 significant_pairs_holm.append(f\"  {model1} vs {model2} (p_orig={p_val_original:.4f}, p_holm={p_val_corrected:.4f}) - ошибка RMSE\")\n",
    "\n",
    "\n",
    "    if significant_pairs_holm:\n",
    "        significant_pairs_holm.sort()\n",
    "        for pair in significant_pairs_holm: print(pair)\n",
    "    else:\n",
    "        print(\"  Нет.\")\n",
    "\n",
    "print(\"\\n--- Тест Диболда-Мариано завершен ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1746743174281,
     "user": {
      "displayName": "Юрий Зиняков",
      "userId": "03392600535050190679"
     },
     "user_tz": -180
    },
    "id": "m62ggtG77JnB",
    "outputId": "7ea08368-3a43-4b49-970f-f3a76c1dbe56"
   },
   "outputs": [],
   "source": [
    "# --- ЯЧЕЙКА ДЛЯ СОХРАНЕНИЯ ПРОГНОЗОВ В EXCEL ---\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Определяем, какие прогнозы моделей мы хотим сохранить\n",
    "#    Возьмем тот же список, что и для DM-теста, или любой другой нужный набор.\n",
    "models_to_save = ['ARIMA', 'LSTM', 'Mean', 'Median', 'Trend', # Добавим все бенчмарки\n",
    "                  'RF_Recursive', 'XGB_Recursive',\n",
    "                  'Lasso_Recursive', 'Ridge_Recursive', # Линейные ML\n",
    "                  'Blend_ARIMA_Trees',\n",
    "                  'ARIMA+XGB_err_Rec_Tuned'] # Твой лучший гибрид\n",
    "                  # Добавь сюда 'ARIMA+XGB_err_Rec', если хочешь сохранить и его для сравнения\n",
    "\n",
    "# 2. Убедимся, что y_test (реальные значения) доступен и имеет правильный индекс\n",
    "#    Предполагаем, что y_test - это pd.Series с DatetimeIndex тестового периода\n",
    "if 'y_test' not in locals() or not isinstance(y_test, pd.Series):\n",
    "    print(\"Ошибка: Переменная y_test (реальные значения) не найдена или имеет неверный тип.\")\n",
    "    # Можно попытаться ее восстановить, если есть test_values и test.index\n",
    "    if 'test_values' in locals() and 'test' in locals() and hasattr(test, 'index'):\n",
    "        try:\n",
    "            y_test_restored = pd.Series(test_values, index=test.index[:len(test_values)])\n",
    "            if not y_test_restored.empty:\n",
    "                 y_test = y_test_restored # Восстанавливаем y_test\n",
    "                 print(\"Переменная y_test восстановлена.\")\n",
    "            else:\n",
    "                 raise ValueError(\"Не удалось восстановить y_test.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось восстановить y_test: {e}\")\n",
    "            # Здесь можно либо прервать выполнение, либо продолжить без y_test\n",
    "            # Для сохранения только прогнозов можно и без y_test, но с ним полезнее\n",
    "else:\n",
    "    print(\"Переменная y_test найдена.\")\n",
    "\n",
    "\n",
    "# 3. Создаем DataFrame для сохранения\n",
    "#    Индекс будет датами тестового периода\n",
    "try:\n",
    "    # Попытаемся использовать индекс из y_test, если он есть и корректен\n",
    "    if 'y_test' in locals() and not y_test.empty:\n",
    "        forecast_dates_index = y_test.index[:test_months] # test_months должно быть определено\n",
    "    # Иначе, если y_test нет, но есть test_ml (из блока подготовки ML данных)\n",
    "    elif 'test_ml' in locals() and not test_ml.empty:\n",
    "        forecast_dates_index = test_ml.index[:test_months]\n",
    "    # Иначе, если есть просто test (из самого начала)\n",
    "    elif 'test' in locals() and not test.empty:\n",
    "         forecast_dates_index = test.index[:test_months]\n",
    "    else:\n",
    "        raise ValueError(\"Не удалось определить индекс для дат прогнозов. Убедитесь, что y_test, test_ml или test существуют.\")\n",
    "\n",
    "    df_all_forecasts = pd.DataFrame(index=forecast_dates_index)\n",
    "\n",
    "    # Добавляем реальные значения, если y_test существует\n",
    "    if 'y_test' in locals() and not y_test.empty:\n",
    "        df_all_forecasts['Actual'] = y_test.values[:len(df_all_forecasts)] # Убедимся, что длина совпадает\n",
    "    else:\n",
    "        print(\"Предупреждение: Реальные значения y_test не будут сохранены.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при создании DataFrame для сохранения: {e}\")\n",
    "    # Прерываем, так как без индекса или y_test сохранение будет неполноценным\n",
    "    raise SystemExit(\"Прерывание из-за ошибки подготовки DataFrame для сохранения.\")\n",
    "\n",
    "\n",
    "# 4. Добавляем прогнозы каждой модели в DataFrame\n",
    "#    Предполагаем, что `recursive_forecasts` - это словарь, где ключ - имя модели, значение - numpy array прогноза\n",
    "if 'recursive_forecasts' not in locals():\n",
    "    raise NameError(\"Словарь recursive_forecasts не найден!\")\n",
    "\n",
    "for model_name in models_to_save:\n",
    "    if model_name in recursive_forecasts:\n",
    "        forecast_values = recursive_forecasts[model_name]\n",
    "        # Обрезаем или дополняем NaN, если длина прогноза не совпадает с длиной индекса\n",
    "        if len(forecast_values) == len(df_all_forecasts):\n",
    "            df_all_forecasts[model_name] = forecast_values\n",
    "        elif len(forecast_values) > len(df_all_forecasts):\n",
    "            df_all_forecasts[model_name] = forecast_values[:len(df_all_forecasts)]\n",
    "            print(f\"Предупреждение: Прогноз для {model_name} был длиннее тестового периода и был обрезан.\")\n",
    "        else: # len(forecast_values) < len(df_all_forecasts)\n",
    "            padded_forecast = np.full(len(df_all_forecasts), np.nan)\n",
    "            padded_forecast[:len(forecast_values)] = forecast_values\n",
    "            df_all_forecasts[model_name] = padded_forecast\n",
    "            print(f\"Предупреждение: Прогноз для {model_name} был короче тестового периода и был дополнен NaN.\")\n",
    "    else:\n",
    "        print(f\"Предупреждение: Прогноз для модели '{model_name}' не найден в recursive_forecasts. Пропускаем.\")\n",
    "\n",
    "# 5. Определяем имя файла\n",
    "#    Используем train_do (дата начала тестового периода) для уникальности имени\n",
    "#    Предполагаем, что train_do существует и содержит строку типа 'YYYY-MM-DD'\n",
    "if 'train_do' not in locals() or not isinstance(train_do, str):\n",
    "    print(\"Предупреждение: Переменная train_do (дата начала теста) не найдена. Используется стандартное имя файла.\")\n",
    "    file_name_excel = \"Прогнозы_моделей.xlsx\"\n",
    "else:\n",
    "    try:\n",
    "        # Извлекаем месяц и год из train_do\n",
    "        # Это предполагает, что train_do в формате 'YYYY-MM-DD'\n",
    "        year_month_str = pd.to_datetime(train_do).strftime('%B_%Y') # Например, 'Февраль_2023'\n",
    "        file_name_excel = f\"Прогнозы_{year_month_str}.xlsx\"\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при форматировании имени файла из train_do: {e}. Используется стандартное имя.\")\n",
    "        file_name_excel = \"Прогнозы_моделей.xlsx\"\n",
    "\n",
    "\n",
    "# 6. Сохраняем DataFrame в Excel\n",
    "try:\n",
    "    df_all_forecasts.to_excel(file_name_excel)\n",
    "    print(f\"\\nПрогнозы успешно сохранены в файл: {file_name_excel}\")\n",
    "    # Выведем первые несколько строк сохраненного DataFrame для проверки\n",
    "    print(\"\\nПервые 5 строк сохраненных данных:\")\n",
    "    print(df_all_forecasts.head())\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении файла Excel: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPjvYIWIkcc3squ8VKfPTRf",
   "mount_file_id": "1eSlN1t4JjWJfcm36rPI_q9uoMdbBmYTF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
